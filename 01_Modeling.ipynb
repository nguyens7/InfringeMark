{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TM_A</th>\n",
       "      <th>TM_B</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Simoniz</td>\n",
       "      <td>Permanize</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Magnavoc</td>\n",
       "      <td>Multivox</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Zirco</td>\n",
       "      <td>Cozirc</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Platinum Puff</td>\n",
       "      <td>Platinum Plus</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Maternity Yours</td>\n",
       "      <td>Your Maternity Shop</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Flossies</td>\n",
       "      <td>Flossbone</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hypnotiq</td>\n",
       "      <td>Hopnotic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Woody Stout</td>\n",
       "      <td>Woody Brown Ale</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Frickin’ Chicken</td>\n",
       "      <td>Flip’n Chicken</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Alair</td>\n",
       "      <td>Holaira</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Seiko</td>\n",
       "      <td>Seycos</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Can</td>\n",
       "      <td>Canya</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Kresco</td>\n",
       "      <td>Cresco</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Intelect</td>\n",
       "      <td>Entelec</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Starbucks</td>\n",
       "      <td>Sambucks</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>MikeRoweSoft</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Tailored T</td>\n",
       "      <td>Tailor-Tee</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Point</td>\n",
       "      <td>Poynt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>K-9</td>\n",
       "      <td>Canine</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Kuf’N Kolar</td>\n",
       "      <td>Cuff &amp; Collar Cleaner</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                TM_A                   TM_B  target\n",
       "0            Simoniz              Permanize       1\n",
       "1           Magnavoc               Multivox       1\n",
       "2              Zirco                 Cozirc       1\n",
       "3      Platinum Puff          Platinum Plus       1\n",
       "4    Maternity Yours    Your Maternity Shop       1\n",
       "5           Flossies              Flossbone       1\n",
       "6           Hypnotiq               Hopnotic       1\n",
       "7        Woody Stout        Woody Brown Ale       1\n",
       "8   Frickin’ Chicken         Flip’n Chicken       1\n",
       "9              Alair                Holaira       1\n",
       "10             Seiko                 Seycos       1\n",
       "11               Can                  Canya       1\n",
       "12            Kresco                 Cresco       1\n",
       "13          Intelect                Entelec       1\n",
       "14         Starbucks               Sambucks       1\n",
       "15         Microsoft           MikeRoweSoft       1\n",
       "16        Tailored T             Tailor-Tee       1\n",
       "17             Point                  Poynt       1\n",
       "18               K-9                 Canine       1\n",
       "19       Kuf’N Kolar  Cuff & Collar Cleaner       1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cases = pd.read_csv('Data.nosync/Similar_TM.csv')\n",
    "cases.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unidecode\n",
    "from fuzzywuzzy import fuzz\n",
    "import jellyfish\n",
    "\n",
    "from abydos.distance import (IterativeSubString, BISIM, DiscountedLevenshtein, Prefix, LCSstr, MLIPNS, Strcmp95,\n",
    "MRA, Editex, SAPS, FlexMetric, JaroWinkler, HigueraMico, Sift4, Eudex, ALINE, PhoneticEditDistance)\n",
    "\n",
    "from abydos.phonetic import PSHPSoundexFirst, Ainsworth\n",
    "pshp_soundex_first = PSHPSoundexFirst()\n",
    "pe = Ainsworth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "iss = IterativeSubString()\n",
    "bisim = BISIM()\n",
    "dlev = DiscountedLevenshtein()\n",
    "prefix = Prefix()\n",
    "lcs = LCSstr()\n",
    "mlipns = MLIPNS()\n",
    "strcmp95 = Strcmp95()\n",
    "mra = MRA()\n",
    "editex = Editex()\n",
    "saps = SAPS()\n",
    "flexmetric = FlexMetric()\n",
    "jaro = JaroWinkler(mode='Jaro')\n",
    "higuera_mico = HigueraMico()\n",
    "sift4 = Sift4()\n",
    "eudex = Eudex()\n",
    "aline = ALINE()\n",
    "phonetic_edit = PhoneticEditDistance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "algos = [iss, bisim, dlev, prefix, lcs, mlipns, strcmp95, mra, editex, saps, flexmetric, jaro, higuera_mico, sift4, eudex,\n",
    "         aline, phonetic_edit]\n",
    "\n",
    "algo_names = ['iterativesubstring', 'bisim', 'discountedlevenshtein', 'prefix', 'lcsstr', 'mlipns', 'strcmp95', 'mra',\n",
    "              'editex', 'saps', 'flexmetric', 'jaro', 'higueramico', 'sift4', 'eudex', 'aline',\n",
    "              'phoneticeditdistance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abydos.phones import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_ipa(name_a, name_b):\n",
    "    feat1 = ipa_to_features(pe.encode(name_a))\n",
    "    feat2 = ipa_to_features(pe.encode(name_b))\n",
    "    score = sum(cmp_features(f1, f2) for f1, f2 in zip(feat1, feat2))/len(feat1)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def featurize(df):\n",
    "    if len(df.columns)==3:\n",
    "        df.columns=['a', 'b', 'target']\n",
    "    elif len(df.columns)==2:\n",
    "        df.columns=['a', 'b']\n",
    "    else:\n",
    "        df = df.rename(columns={df.columns[0]: 'a', df.columns[1]: 'b' })\n",
    "        \n",
    "    df['TM_A'] = df.apply(lambda row: re.sub(\n",
    "        '[^a-zA-Z]+', '', unidecode.unidecode(row['a']).lower()), axis=1)\n",
    "    df['TM_B'] = df.apply(lambda row: re.sub(\n",
    "        '[^a-zA-Z]+', '', unidecode.unidecode(row['b']).lower()), axis=1)\n",
    "    \n",
    "\n",
    "    df['partial'] = df.apply(lambda row: fuzz.partial_ratio(row.TM_A,row.TM_B), axis=1)\n",
    "    df['tkn_sort'] = df.apply(lambda row: fuzz.token_sort_ratio(row.TM_A,row.TM_B), axis=1)\n",
    "    df['tkn_set'] = df.apply(lambda row: fuzz.token_set_ratio(row.TM_A,row.TM_B), axis=1)\n",
    "    \n",
    "#     df['sum_ipa'] = df.apply(lambda row: sum_ipa(row.TM_A,row.TM_B), axis=1)\n",
    "    \n",
    "    # Jellyfish levenshtein\n",
    "    df['levenshtein']= df.apply(lambda row: jellyfish.levenshtein_distance(row.TM_A,row.TM_B), axis=1)\n",
    "    # Scale Levenshtein column\n",
    "    scaler = MinMaxScaler()\n",
    "    df['levenshtein'] = scaler.fit_transform(df['levenshtein'].values.reshape(-1,1))\n",
    "\n",
    "    # Jellyfish phoneme\n",
    "    df['metaphone'] = df.apply(\n",
    "        lambda row: 1 if jellyfish.metaphone(row.TM_A)==jellyfish.metaphone(row.TM_B) else 0, axis=1)\n",
    "    df['nysiis'] = df.apply(\n",
    "        lambda row: 1 if jellyfish.nysiis(row.TM_A)==jellyfish.nysiis(row.TM_B) else 0, axis=1)\n",
    "    df['mtch_rtng_cdx'] = df.apply(\n",
    "        lambda row: 1 if jellyfish.match_rating_codex(row.TM_A)==jellyfish.match_rating_codex(row.TM_B) else 0, axis=1)\n",
    "    \n",
    "    df['pshp_soundex_first'] = df.apply(\n",
    "        lambda row: 1 if pshp_soundex_first.encode(row.TM_A)==pshp_soundex_first.encode(row.TM_B) else 0, axis=1)\n",
    "    \n",
    "    for i, algo in enumerate(algos):\n",
    "            df[algo_names[i]] = df.progress_apply(lambda row: algo.sim(row.TM_A, row.TM_B), axis=1)\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# featurize(cases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Balancing  \n",
    "We can see that the classes are imbalanced, there are more instances of trademark invalidation than are dismissals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fa8b593d4c0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cases['target'].value_counts()[:2].plot(kind='bar')\n",
    "\n",
    "# plt.savefig('TM_Unbalanced.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "import random\n",
    "random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TM_A</th>\n",
       "      <th>TM_B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60 40 20</td>\n",
       "      <td>OPARUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Xtreme Makeup</td>\n",
       "      <td>EDOMIGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SEARCH SAVVY PR</td>\n",
       "      <td>ESSENTRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The University of Law</td>\n",
       "      <td>Jaded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shortlyster</td>\n",
       "      <td>CONNECT.COM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>Dylan</td>\n",
       "      <td>Zlide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>House of Silk</td>\n",
       "      <td>HiGain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>MOSCANY</td>\n",
       "      <td>BIOBOOSTER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>Next Deal Shop</td>\n",
       "      <td>PAPA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>CAMcap</td>\n",
       "      <td>AADVANTAGE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      TM_A         TM_B\n",
       "0                 60 40 20       OPARUS\n",
       "1            Xtreme Makeup      EDOMIGE\n",
       "2          SEARCH SAVVY PR     ESSENTRA\n",
       "3    The University of Law        Jaded\n",
       "4              Shortlyster  CONNECT.COM\n",
       "..                     ...          ...\n",
       "295                  Dylan        Zlide\n",
       "296          House of Silk       HiGain\n",
       "297                MOSCANY   BIOBOOSTER\n",
       "298         Next Deal Shop         PAPA\n",
       "299                 CAMcap   AADVANTAGE\n",
       "\n",
       "[300 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use combinatorics to generate negative class\n",
    "pos_cases = cases[cases['target'] == 1]\n",
    "\n",
    "case_names = pos_cases.loc[:, 'TM_A':'TM_B'].values.tolist()\n",
    "unique_cases = list(set([item for items in case_names for item in items]))\n",
    "alt_pairs = list(zip(pos_cases.TM_A, pos_cases.TM_B))+ list(zip(pos_cases.TM_B, pos_cases.TM_A))\n",
    "comb = list(combinations(unique_cases, 2))\n",
    "nonmatch_cases = list(set(comb) - set(alt_pairs))\n",
    "# Undersample the negative class for 1:4 class imbalance instead of 1:1000 extreme class imbalance\n",
    "nonmatch_cases = pd.DataFrame(random.choices(nonmatch_cases, k=300), columns=['TM_A', 'TM_B']) # Originally was 1200\n",
    "\n",
    "nonmatch_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive class ratio 1:1\n"
     ]
    }
   ],
   "source": [
    "print('positive class ratio 1:{}'.format(int(len(nonmatch_cases)/len(pos_cases))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TM_A</th>\n",
       "      <th>TM_B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>FINASTRA</td>\n",
       "      <td>Verve Design</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>WELLBOX</td>\n",
       "      <td>RED BULL BBQ GRILLS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>AMMA</td>\n",
       "      <td>EASYSAIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>No More Tangles</td>\n",
       "      <td>TOMMY HERITAGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Horse of London</td>\n",
       "      <td>GOGO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>Alair</td>\n",
       "      <td>Panda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>BLUE.COM</td>\n",
       "      <td>Dank Vapes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>Dr. Wolff</td>\n",
       "      <td>Illumina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Eden Pure</td>\n",
       "      <td>VESPER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>Thirty forty fifty</td>\n",
       "      <td>BLEPHACARE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Holaira</td>\n",
       "      <td>TREADSTONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>SIMTEC</td>\n",
       "      <td>HARD CORE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>F.A.B.</td>\n",
       "      <td>Fashion tan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Starbucks</td>\n",
       "      <td>OFO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>QIS</td>\n",
       "      <td>IMPERIAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Entelec</td>\n",
       "      <td>ALEXANDER OF PARIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>PING</td>\n",
       "      <td>Mideltone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>IT’S AN ADDICTION</td>\n",
       "      <td>PONIM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>Kool shot</td>\n",
       "      <td>TOMMY HERITAGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>BRITISH GAS</td>\n",
       "      <td>The Science of Stoke</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   TM_A                  TM_B\n",
       "165            FINASTRA          Verve Design\n",
       "187             WELLBOX   RED BULL BBQ GRILLS\n",
       "289                AMMA              EASYSAIL\n",
       "150     No More Tangles        TOMMY HERITAGE\n",
       "197     Horse of London                  GOGO\n",
       "218               Alair                 Panda\n",
       "185            BLUE.COM            Dank Vapes\n",
       "262           Dr. Wolff              Illumina\n",
       "56            Eden Pure                VESPER\n",
       "282  Thirty forty fifty            BLEPHACARE\n",
       "61              Holaira            TREADSTONE\n",
       "193              SIMTEC             HARD CORE\n",
       "236              F.A.B.           Fashion tan\n",
       "107           Starbucks                   OFO\n",
       "93                  QIS              IMPERIAL\n",
       "15              Entelec    ALEXANDER OF PARIS\n",
       "47                 PING             Mideltone\n",
       "237   IT’S AN ADDICTION                 PONIM\n",
       "160           Kool shot        TOMMY HERITAGE\n",
       "221         BRITISH GAS  The Science of Stoke"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonmatch_cases.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TM_A</th>\n",
       "      <th>TM_B</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Simoniz</td>\n",
       "      <td>Permanize</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Magnavoc</td>\n",
       "      <td>Multivox</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Zirco</td>\n",
       "      <td>Cozirc</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Platinum Puff</td>\n",
       "      <td>Platinum Plus</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Maternity Yours</td>\n",
       "      <td>Your Maternity Shop</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>Lilton</td>\n",
       "      <td>Wilton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>Nutricia</td>\n",
       "      <td>Nutritea</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>Glenreidh</td>\n",
       "      <td>An Reidhe</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>No Gunk No Junk</td>\n",
       "      <td>No Gunk Just Funk</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>e-Relief</td>\n",
       "      <td>LIGHT RELIEF</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>657 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                TM_A                 TM_B  target\n",
       "0            Simoniz            Permanize       1\n",
       "1           Magnavoc             Multivox       1\n",
       "2              Zirco               Cozirc       1\n",
       "3      Platinum Puff        Platinum Plus       1\n",
       "4    Maternity Yours  Your Maternity Shop       1\n",
       "..               ...                  ...     ...\n",
       "352           Lilton               Wilton       0\n",
       "353         Nutricia             Nutritea       0\n",
       "354        Glenreidh            An Reidhe       0\n",
       "355  No Gunk No Junk    No Gunk Just Funk       0\n",
       "356         e-Relief         LIGHT RELIEF       0\n",
       "\n",
       "[657 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Negative Class\n",
    "nonmatch_cases['target'] = 0\n",
    "df = pd.concat([pos_cases, nonmatch_cases])\n",
    "# non_match_cases = None\n",
    "# pos_cases = None\n",
    "\n",
    "# Add true negatives\n",
    "neg_cases = cases[cases['target'] == 0]\n",
    "class_balanced = pd.concat([df, neg_cases])\n",
    "\n",
    "class_balanced.sample(20)\n",
    "\n",
    "class_balanced\n",
    "\n",
    "# class_balanced[class_balanced['TM_B'].str.len()!=0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fa8b5a13040>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_balanced['target'].value_counts()[:2].plot(kind='bar')\n",
    "\n",
    "# plt.savefig('TM_Balanced.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-213a59b7ad7e>:1: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n",
      "/Users/seannguyen/opt/anaconda3/lib/python3.8/site-packages/tqdm/std.py:668: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12091b1c53394193b871f4bb3c7bf6a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=657.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ce4582f2a3d4f93ae1ae50a24bf0a9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=657.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d3f064b69ee42cba7815df68f0e61ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=657.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a328c74052ae42198c6518e65a1fdce9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=657.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a5edb91328f4059843d1373735031d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=657.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e4adc917aa1408ba46116304ef78853",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=657.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f44c9c5a93744488daf39a83047b8d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=657.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b4000509bed4940847aca8b183d69c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=657.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f80d8f2c47754d86a3ec097c7e352a45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=657.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71f54eb9b9f64a23ad9c7b686f6e813b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=657.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28abeda3bf5449d697f771958c410486",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=657.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34e42b805d1c46279eb5999656f746e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=657.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16694287ab704a5e949dc8fd0a955e18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=657.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "152d303d8ec94adbac66eced149da908",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=657.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04f27b3e8e9b41c599a855134a7fd814",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=657.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64a5ac5440464300ba2f005dacd61469",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=657.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1ff4de0291a4e278c2f2cab593c4a4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=657.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>target</th>\n",
       "      <th>TM_A</th>\n",
       "      <th>TM_B</th>\n",
       "      <th>partial</th>\n",
       "      <th>tkn_sort</th>\n",
       "      <th>tkn_set</th>\n",
       "      <th>levenshtein</th>\n",
       "      <th>metaphone</th>\n",
       "      <th>...</th>\n",
       "      <th>mra</th>\n",
       "      <th>editex</th>\n",
       "      <th>saps</th>\n",
       "      <th>flexmetric</th>\n",
       "      <th>jaro</th>\n",
       "      <th>higueramico</th>\n",
       "      <th>sift4</th>\n",
       "      <th>eudex</th>\n",
       "      <th>aline</th>\n",
       "      <th>phoneticeditdistance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>Harry’s Bar</td>\n",
       "      <td>Harry Gordon’s Bar</td>\n",
       "      <td>1</td>\n",
       "      <td>harrysbar</td>\n",
       "      <td>harrygordonsbar</td>\n",
       "      <td>67</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.792593</td>\n",
       "      <td>0.510739</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.978922</td>\n",
       "      <td>0.476471</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>DUNSTON</td>\n",
       "      <td>Willow Tree Gin</td>\n",
       "      <td>0</td>\n",
       "      <td>dunston</td>\n",
       "      <td>willowtreegin</td>\n",
       "      <td>29</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.388462</td>\n",
       "      <td>0.313187</td>\n",
       "      <td>0.028108</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.734804</td>\n",
       "      <td>0.263492</td>\n",
       "      <td>0.482630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>ELYSIUM</td>\n",
       "      <td>JOBZGENIE</td>\n",
       "      <td>0</td>\n",
       "      <td>elysium</td>\n",
       "      <td>jobzgenie</td>\n",
       "      <td>29</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.211111</td>\n",
       "      <td>0.417989</td>\n",
       "      <td>0.063889</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.552941</td>\n",
       "      <td>0.255319</td>\n",
       "      <td>0.600358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>BLUE.COM</td>\n",
       "      <td>Dank Vapes</td>\n",
       "      <td>0</td>\n",
       "      <td>bluecom</td>\n",
       "      <td>dankvapes</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.272222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018434</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.796569</td>\n",
       "      <td>0.225490</td>\n",
       "      <td>0.623656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>INVESTED. TOGETHER.</td>\n",
       "      <td>PIC NIC</td>\n",
       "      <td>0</td>\n",
       "      <td>investedtogether</td>\n",
       "      <td>picnic</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.362500</td>\n",
       "      <td>0.486111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.488235</td>\n",
       "      <td>0.236364</td>\n",
       "      <td>0.339718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>LA MERCI</td>\n",
       "      <td>MERCI</td>\n",
       "      <td>0</td>\n",
       "      <td>lamerci</td>\n",
       "      <td>merci</td>\n",
       "      <td>100</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.690476</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.803922</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>LOCO</td>\n",
       "      <td>LOKA</td>\n",
       "      <td>1</td>\n",
       "      <td>loco</td>\n",
       "      <td>loka</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.998039</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.943548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>PRO GAINS</td>\n",
       "      <td>HAMILTON</td>\n",
       "      <td>0</td>\n",
       "      <td>progains</td>\n",
       "      <td>hamilton</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.145960</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.655882</td>\n",
       "      <td>0.297727</td>\n",
       "      <td>0.618952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>INTERCONTEC INFINITE CONNECTIONS\\t</td>\n",
       "      <td>INTERCONNECT SOLUTIONS</td>\n",
       "      <td>0</td>\n",
       "      <td>intercontecinfiniteconnections</td>\n",
       "      <td>interconnectsolutions</td>\n",
       "      <td>71</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>0.671667</td>\n",
       "      <td>0.763492</td>\n",
       "      <td>0.517038</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.550617</td>\n",
       "      <td>0.682796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Camel activ</td>\n",
       "      <td>Camel Capa</td>\n",
       "      <td>1</td>\n",
       "      <td>camelactiv</td>\n",
       "      <td>camelcapa</td>\n",
       "      <td>67</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.778307</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.992647</td>\n",
       "      <td>0.672222</td>\n",
       "      <td>0.780645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>SILENT POOL</td>\n",
       "      <td>Oliver Sweeney</td>\n",
       "      <td>0</td>\n",
       "      <td>silentpool</td>\n",
       "      <td>oliversweeney</td>\n",
       "      <td>30</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.357692</td>\n",
       "      <td>0.399145</td>\n",
       "      <td>0.133450</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.499020</td>\n",
       "      <td>0.322034</td>\n",
       "      <td>0.681141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>TRANSICS</td>\n",
       "      <td>TRINSIC</td>\n",
       "      <td>1</td>\n",
       "      <td>transics</td>\n",
       "      <td>trinsic</td>\n",
       "      <td>86</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.762500</td>\n",
       "      <td>0.813492</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.817647</td>\n",
       "      <td>0.822917</td>\n",
       "      <td>0.858871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>T2</td>\n",
       "      <td>T2A</td>\n",
       "      <td>1</td>\n",
       "      <td>t</td>\n",
       "      <td>ta</td>\n",
       "      <td>100</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Alair</td>\n",
       "      <td>Holaira</td>\n",
       "      <td>1</td>\n",
       "      <td>alair</td>\n",
       "      <td>holaira</td>\n",
       "      <td>80</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.671429</td>\n",
       "      <td>0.790476</td>\n",
       "      <td>0.547619</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.795588</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.686636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>DORCHESTER</td>\n",
       "      <td>ROCHESTER</td>\n",
       "      <td>0</td>\n",
       "      <td>dorchester</td>\n",
       "      <td>rochester</td>\n",
       "      <td>89</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.805000</td>\n",
       "      <td>0.929630</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.896774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>GideonsUK</td>\n",
       "      <td>Gideon</td>\n",
       "      <td>1</td>\n",
       "      <td>gideonsuk</td>\n",
       "      <td>gideon</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.677778</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.621032</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.918627</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>UGLY KID CLOTHING UK</td>\n",
       "      <td>KINK</td>\n",
       "      <td>0</td>\n",
       "      <td>uglykidclothinguk</td>\n",
       "      <td>kink</td>\n",
       "      <td>50</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.388235</td>\n",
       "      <td>0.539216</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.604902</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.235294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>PEPE</td>\n",
       "      <td>PEPE’S PIRI PIRI</td>\n",
       "      <td>1</td>\n",
       "      <td>pepe</td>\n",
       "      <td>pepespiripiri</td>\n",
       "      <td>100</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.323077</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.935784</td>\n",
       "      <td>0.298507</td>\n",
       "      <td>0.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>Canvas Lifestyle Retirement Living</td>\n",
       "      <td>AMCAP</td>\n",
       "      <td>0</td>\n",
       "      <td>canvaslifestyleretirementliving</td>\n",
       "      <td>amcap</td>\n",
       "      <td>40</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.248387</td>\n",
       "      <td>0.454480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.808824</td>\n",
       "      <td>0.105325</td>\n",
       "      <td>0.148283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>SPRAY DRY</td>\n",
       "      <td>SUPER DRY</td>\n",
       "      <td>0</td>\n",
       "      <td>spraydry</td>\n",
       "      <td>superdry</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.577778</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.850806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      a                       b  target  \\\n",
       "169                         Harry’s Bar      Harry Gordon’s Bar       1   \n",
       "202                             DUNSTON         Willow Tree Gin       0   \n",
       "109                             ELYSIUM               JOBZGENIE       0   \n",
       "185                            BLUE.COM              Dank Vapes       0   \n",
       "17                  INVESTED. TOGETHER.                 PIC NIC       0   \n",
       "339                            LA MERCI                   MERCI       0   \n",
       "167                                LOCO                    LOKA       1   \n",
       "49                            PRO GAINS                HAMILTON       0   \n",
       "294  INTERCONTEC INFINITE CONNECTIONS\\t  INTERCONNECT SOLUTIONS       0   \n",
       "34                          Camel activ              Camel Capa       1   \n",
       "157                         SILENT POOL          Oliver Sweeney       0   \n",
       "254                            TRANSICS                 TRINSIC       1   \n",
       "37                                   T2                     T2A       1   \n",
       "9                                 Alair                 Holaira       1   \n",
       "334                          DORCHESTER               ROCHESTER       0   \n",
       "67                            GideonsUK                  Gideon       1   \n",
       "28                 UGLY KID CLOTHING UK                    KINK       0   \n",
       "240                                PEPE        PEPE’S PIRI PIRI       1   \n",
       "166  Canvas Lifestyle Retirement Living                   AMCAP       0   \n",
       "291                           SPRAY DRY               SUPER DRY       0   \n",
       "\n",
       "                                TM_A                   TM_B  partial  \\\n",
       "169                        harrysbar        harrygordonsbar       67   \n",
       "202                          dunston          willowtreegin       29   \n",
       "109                          elysium              jobzgenie       29   \n",
       "185                          bluecom              dankvapes       14   \n",
       "17                  investedtogether                 picnic        0   \n",
       "339                          lamerci                  merci      100   \n",
       "167                             loco                   loka       50   \n",
       "49                          progains               hamilton       38   \n",
       "294   intercontecinfiniteconnections  interconnectsolutions       71   \n",
       "34                        camelactiv              camelcapa       67   \n",
       "157                       silentpool          oliversweeney       30   \n",
       "254                         transics                trinsic       86   \n",
       "37                                 t                     ta      100   \n",
       "9                              alair                holaira       80   \n",
       "334                       dorchester              rochester       89   \n",
       "67                         gideonsuk                 gideon      100   \n",
       "28                 uglykidclothinguk                   kink       50   \n",
       "240                             pepe          pepespiripiri      100   \n",
       "166  canvaslifestyleretirementliving                  amcap       40   \n",
       "291                         spraydry               superdry       75   \n",
       "\n",
       "     tkn_sort  tkn_set  levenshtein  metaphone  ...       mra    editex  \\\n",
       "169        75       75     0.171429          0  ...  1.000000  0.633333   \n",
       "202        20       20     0.314286          0  ...  0.000000  0.384615   \n",
       "109        25       25     0.257143          0  ...  0.000000  0.222222   \n",
       "185        12       12     0.257143          0  ...  0.000000  0.111111   \n",
       "17         18       18     0.457143          0  ...  0.000000  0.156250   \n",
       "339        83       83     0.057143          0  ...  0.833333  0.714286   \n",
       "167        50       50     0.057143          1  ...  0.833333  0.750000   \n",
       "49         38       38     0.228571          0  ...  0.000000  0.187500   \n",
       "294        67       67     0.371429          0  ...  1.000000  0.616667   \n",
       "34         63       63     0.114286          0  ...  0.666667  0.600000   \n",
       "157        26       26     0.314286          0  ...  0.000000  0.307692   \n",
       "254        80       80     0.057143          0  ...  0.833333  0.812500   \n",
       "37         67       67     0.028571          1  ...  1.000000  0.500000   \n",
       "9          67       67     0.085714          0  ...  0.833333  0.642857   \n",
       "334        84       84     0.057143          0  ...  0.500000  0.800000   \n",
       "67         80       80     0.085714          0  ...  0.666667  0.666667   \n",
       "28         38       38     0.371429          0  ...  0.000000  0.264706   \n",
       "240        47       47     0.257143          0  ...  0.000000  0.307692   \n",
       "166        11       11     0.828571          0  ...  0.000000  0.096774   \n",
       "291        75       75     0.114286          1  ...  1.000000  0.562500   \n",
       "\n",
       "         saps  flexmetric      jaro  higueramico     sift4     eudex  \\\n",
       "169  0.222222    0.650000  0.792593     0.510739  0.400000  0.978922   \n",
       "202  0.000000    0.388462  0.313187     0.028108  0.076923  0.734804   \n",
       "109  0.000000    0.211111  0.417989     0.063889  0.111111  0.552941   \n",
       "185  0.000000    0.272222  0.000000     0.018434  0.111111  0.796569   \n",
       "17   0.000000    0.362500  0.486111     0.000000  0.125000  0.488235   \n",
       "339  0.500000    0.714286  0.904762     0.690476  0.714286  0.803922   \n",
       "167  0.285714    0.750000  0.666667     0.500000  0.500000  0.998039   \n",
       "49   0.000000    0.100000  0.583333     0.145960  0.375000  0.655882   \n",
       "294  0.311111    0.671667  0.763492     0.517038  0.433333  1.000000   \n",
       "34   0.233333    0.680000  0.778307     0.600000  0.600000  0.992647   \n",
       "157  0.000000    0.357692  0.399145     0.133450  0.153846  0.499020   \n",
       "254  0.607143    0.762500  0.813492     0.750000  0.750000  0.817647   \n",
       "37   0.714286    0.500000  0.833333     0.500000  0.500000  1.000000   \n",
       "9    0.045455    0.671429  0.790476     0.547619  0.571429  0.795588   \n",
       "334  0.366667    0.805000  0.929630     0.800000  0.800000  0.588235   \n",
       "67   0.458333    0.677778  0.888889     0.621032  0.666667  0.918627   \n",
       "28   0.000000    0.388235  0.539216     0.000000  0.117647  0.604902   \n",
       "240  0.000000    0.323077  0.769231     0.000000  0.307692  0.935784   \n",
       "166  0.000000    0.248387  0.454480     0.000000  0.064516  0.808824   \n",
       "291  0.392857    0.575000  0.777778     0.577778  0.750000  0.933333   \n",
       "\n",
       "        aline  phoneticeditdistance  \n",
       "169  0.476471              0.600000  \n",
       "202  0.263492              0.482630  \n",
       "109  0.255319              0.600358  \n",
       "185  0.225490              0.623656  \n",
       "17   0.236364              0.339718  \n",
       "339  0.729730              0.714286  \n",
       "167  0.750000              0.943548  \n",
       "49   0.297727              0.618952  \n",
       "294  0.550617              0.682796  \n",
       "34   0.672222              0.780645  \n",
       "157  0.322034              0.681141  \n",
       "254  0.822917              0.858871  \n",
       "37   0.700000              0.500000  \n",
       "9    0.636364              0.686636  \n",
       "334  0.793103              0.896774  \n",
       "67   0.638298              0.666667  \n",
       "28   0.200000              0.235294  \n",
       "240  0.298507              0.307692  \n",
       "166  0.105325              0.148283  \n",
       "291  0.681818              0.850806  \n",
       "\n",
       "[20 rows x 30 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm.autonotebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "df = featurize(class_balanced)\n",
    "df.sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export clean data to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('Data.nosync/TM_features.csv', index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.target\n",
    "X = df.drop(columns = 'target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train.drop(['a', 'b', 'TM_A', 'TM_B'],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TPOT AutoML pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpot import TPOTClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline_optimizer = TPOTClassifier(\n",
    "#         scoring = 'f1', \n",
    "#         generations=100,\n",
    "#         verbosity=2,\n",
    "#         n_jobs=-1   # Utilizes all available CPU cores\n",
    "#         ) \n",
    "# pipeline_optimizer.fit(X_train.drop(['a', 'b', 'TM_A', 'TM_B'],1), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pipeline_optimizer.score(X_test.drop(['a', 'b', 'TM_A', 'TM_B'], 1), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export TPOT pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline_optimizer.export('tpot_exported_calssifier_pipeline.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load TPOT pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>partial</th>\n",
       "      <th>tkn_sort</th>\n",
       "      <th>tkn_set</th>\n",
       "      <th>levenshtein</th>\n",
       "      <th>metaphone</th>\n",
       "      <th>nysiis</th>\n",
       "      <th>mtch_rtng_cdx</th>\n",
       "      <th>pshp_soundex_first</th>\n",
       "      <th>iterativesubstring</th>\n",
       "      <th>...</th>\n",
       "      <th>mra</th>\n",
       "      <th>editex</th>\n",
       "      <th>saps</th>\n",
       "      <th>flexmetric</th>\n",
       "      <th>jaro</th>\n",
       "      <th>higueramico</th>\n",
       "      <th>sift4</th>\n",
       "      <th>eudex</th>\n",
       "      <th>aline</th>\n",
       "      <th>phoneticeditdistance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.485480</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.671958</td>\n",
       "      <td>0.430556</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.654902</td>\n",
       "      <td>0.602128</td>\n",
       "      <td>0.727599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.897177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>73</td>\n",
       "      <td>73</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.821263</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>0.547619</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.786275</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.634409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.884677</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.873529</td>\n",
       "      <td>0.913978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.951613</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.319149</td>\n",
       "      <td>0.538235</td>\n",
       "      <td>0.687675</td>\n",
       "      <td>0.490372</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.463725</td>\n",
       "      <td>0.589655</td>\n",
       "      <td>0.646110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.943548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.804167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.787500</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.997549</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.973790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.800858</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.741402</td>\n",
       "      <td>0.588889</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.784804</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.655914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.852383</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.469388</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.815873</td>\n",
       "      <td>0.637363</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.995588</td>\n",
       "      <td>0.713415</td>\n",
       "      <td>0.808756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.793397</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.663636</td>\n",
       "      <td>0.689755</td>\n",
       "      <td>0.482071</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.775490</td>\n",
       "      <td>0.491803</td>\n",
       "      <td>0.633431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>657 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     target  partial  tkn_sort  tkn_set  levenshtein  metaphone  nysiis  \\\n",
       "0         1       57        50       50     0.142857          0       0   \n",
       "1         1       38        38       38     0.142857          0       0   \n",
       "2         1       89        73       73     0.085714          0       0   \n",
       "3         1       83        83       83     0.085714          0       0   \n",
       "4         1       74        65       65     0.257143          0       0   \n",
       "..      ...      ...       ...      ...          ...        ...     ...   \n",
       "352       0       83        83       83     0.028571          0       0   \n",
       "353       0       75        75       75     0.057143          0       0   \n",
       "354       0       80        71       71     0.114286          0       0   \n",
       "355       0       67        77       77     0.142857          0       0   \n",
       "356       0       86        67       67     0.142857          0       0   \n",
       "\n",
       "     mtch_rtng_cdx  pshp_soundex_first  iterativesubstring  ...       mra  \\\n",
       "0                0                   0            0.485480  ...  0.666667   \n",
       "1                0                   0            0.050000  ...  0.500000   \n",
       "2                0                   0            0.821263  ...  0.833333   \n",
       "3                0                   1            0.884677  ...  0.500000   \n",
       "4                0                   0            0.951613  ...  0.000000   \n",
       "..             ...                 ...                 ...  ...       ...   \n",
       "352              0                   0            0.897436  ...  0.833333   \n",
       "353              0                   1            0.804167  ...  0.833333   \n",
       "354              0                   0            0.800858  ...  0.666667   \n",
       "355              0                   1            0.852383  ...  0.833333   \n",
       "356              0                   0            0.793397  ...  0.500000   \n",
       "\n",
       "       editex      saps  flexmetric      jaro  higueramico     sift4  \\\n",
       "0    0.555556  0.137931    0.566667  0.671958     0.430556  0.444444   \n",
       "1    0.500000  0.304348    0.400000  0.583333     0.375000  0.375000   \n",
       "2    0.500000  0.428571    0.600000  0.822222     0.547619  0.666667   \n",
       "3    0.833333  0.666667    0.833333  0.888889     0.769231  0.833333   \n",
       "4    0.588235  0.319149    0.538235  0.687675     0.490372  0.588235   \n",
       "..        ...       ...         ...       ...          ...       ...   \n",
       "352  0.833333  0.500000    0.833333  0.822222     0.833333  0.833333   \n",
       "353  0.812500  0.565217    0.787500  0.833333     0.750000  0.750000   \n",
       "354  0.666667  0.310345    0.666667  0.741402     0.588889  0.666667   \n",
       "355  0.678571  0.469388    0.700000  0.815873     0.637363  0.714286   \n",
       "356  0.636364  0.166667    0.663636  0.689755     0.482071  0.363636   \n",
       "\n",
       "        eudex     aline  phoneticeditdistance  \n",
       "0    0.654902  0.602128              0.727599  \n",
       "1    0.916667  0.545455              0.897177  \n",
       "2    0.786275  0.705882              0.634409  \n",
       "3    1.000000  0.873529              0.913978  \n",
       "4    0.463725  0.589655              0.646110  \n",
       "..        ...       ...                   ...  \n",
       "352  0.866667  0.823529              0.943548  \n",
       "353  0.997549  0.937500              0.973790  \n",
       "354  0.784804  0.705882              0.655914  \n",
       "355  0.995588  0.713415              0.808756  \n",
       "356  0.775490  0.491803              0.633431  \n",
       "\n",
       "[657 rows x 26 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_TPOT = df.drop(columns = ['a','b','TM_A','TM_B'])\n",
    "df_TPOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1,\n",
       "       0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from tpot.builtins import StackingEstimator\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from copy import copy\n",
    "\n",
    "# NOTE: Make sure that the outcome column is labeled 'target' in the data file\n",
    "tpot_data = df_TPOT\n",
    "features = tpot_data.drop('target', axis=1)\n",
    "training_features, testing_features, training_target, testing_target = \\\n",
    "            train_test_split(features, tpot_data['target'], random_state=None)\n",
    "\n",
    "# Average CV score on the training set was: 0.8945711361541637\n",
    "exported_pipeline = make_pipeline(\n",
    "    make_union(\n",
    "        FunctionTransformer(copy),\n",
    "        FunctionTransformer(copy)\n",
    "    ),\n",
    "    GradientBoostingClassifier(learning_rate=0.01, max_depth=3, max_features=0.5, min_samples_leaf=10, min_samples_split=3, n_estimators=100, subsample=0.9500000000000001)\n",
    ")\n",
    "\n",
    "exported_pipeline.fit(training_features, training_target)\n",
    "results = exported_pipeline.predict(testing_features)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_model_1(X_train, y_train, X_test, export = False) :\n",
    "    exported_pipeline = make_pipeline(\n",
    "    GradientBoostingClassifier(\n",
    "        learning_rate=0.01, \n",
    "        max_depth=3, max_features=0.5,\n",
    "        min_samples_leaf=10, min_samples_split=3, \n",
    "        n_estimators=100, subsample=0.9500000000000001)\n",
    "    )\n",
    "\n",
    "    exported_pipeline.fit(X_train, y_train)\n",
    "    if export==True:\n",
    "        return exported_pipeline\n",
    "    else:\n",
    "        y_pred = exported_pipeline.predict_proba(X_test)\n",
    "        return [p[1] for p in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.35112025409619513,\n",
       " 0.6702700201918589,\n",
       " 0.16323738118861,\n",
       " 0.6330568226983103,\n",
       " 0.16323738118861,\n",
       " 0.626720196506135,\n",
       " 0.7053552309896098,\n",
       " 0.16323738118861,\n",
       " 0.6874011722938973,\n",
       " 0.7025578206353692,\n",
       " 0.2557027149778569,\n",
       " 0.6737335658025978,\n",
       " 0.671052669720941,\n",
       " 0.16323738118861,\n",
       " 0.16659745609034987,\n",
       " 0.16323738118861,\n",
       " 0.16323738118861,\n",
       " 0.18526761802516206,\n",
       " 0.6995389474924879,\n",
       " 0.6679158647370822,\n",
       " 0.5888994626719004,\n",
       " 0.6593520385548661,\n",
       " 0.7535091640685181,\n",
       " 0.16304445525505942,\n",
       " 0.16323738118861,\n",
       " 0.2549397396300578,\n",
       " 0.6651310331291863,\n",
       " 0.19509117516559993,\n",
       " 0.16323738118861,\n",
       " 0.16390736867760353,\n",
       " 0.7447419348282912,\n",
       " 0.7222551924488118,\n",
       " 0.16323738118861,\n",
       " 0.5622943080171677,\n",
       " 0.7391024446409264,\n",
       " 0.5710079684685267,\n",
       " 0.6234979616189069,\n",
       " 0.5900421681347799,\n",
       " 0.7447419348282912,\n",
       " 0.6591115425354162,\n",
       " 0.33992711741647585,\n",
       " 0.16591865470841616,\n",
       " 0.7430660226586402,\n",
       " 0.16591865470841616,\n",
       " 0.70214526981173,\n",
       " 0.16323738118861,\n",
       " 0.6866767032568911,\n",
       " 0.7430660226586402,\n",
       " 0.6577363923506447,\n",
       " 0.7496576903824551,\n",
       " 0.31335224197618466,\n",
       " 0.6890812692585625,\n",
       " 0.7467665536207613,\n",
       " 0.16323738118861,\n",
       " 0.6984120859122169,\n",
       " 0.668359768196652,\n",
       " 0.16323738118861,\n",
       " 0.6708088163973545,\n",
       " 0.6655902580341899,\n",
       " 0.16591865470841616,\n",
       " 0.16323738118861,\n",
       " 0.16323738118861,\n",
       " 0.6672686910515206,\n",
       " 0.7158080836212587,\n",
       " 0.6271467845675407,\n",
       " 0.6186190033049483,\n",
       " 0.6687790591198652,\n",
       " 0.6993899758981252,\n",
       " 0.7027543984917878,\n",
       " 0.16323738118861,\n",
       " 0.2636327356519036,\n",
       " 0.6799883845355562,\n",
       " 0.5929512801169418,\n",
       " 0.16304445525505942,\n",
       " 0.16323738118861,\n",
       " 0.16323738118861,\n",
       " 0.17387686211223083,\n",
       " 0.663650955240092,\n",
       " 0.6805733405873156,\n",
       " 0.6982595567689206,\n",
       " 0.6659003069241644,\n",
       " 0.17799940954873636,\n",
       " 0.5726697167786771,\n",
       " 0.16323738118861,\n",
       " 0.16323738118861,\n",
       " 0.664031724093067,\n",
       " 0.16323738118861,\n",
       " 0.7254693245569978,\n",
       " 0.6565156018839104,\n",
       " 0.3327771780483858,\n",
       " 0.6576600702482841,\n",
       " 0.6668916853470854,\n",
       " 0.19752328782820255,\n",
       " 0.693915227987695,\n",
       " 0.16323738118861,\n",
       " 0.6975886283011216,\n",
       " 0.5662044327455833,\n",
       " 0.6807820606906285,\n",
       " 0.6538124340419055,\n",
       " 0.57474599971677,\n",
       " 0.18561999913676192,\n",
       " 0.691257988186979,\n",
       " 0.6580759433905009,\n",
       " 0.6751422816475049,\n",
       " 0.7535091640685181,\n",
       " 0.698132047476804,\n",
       " 0.6974791981540862,\n",
       " 0.7013949782301033,\n",
       " 0.16323738118861,\n",
       " 0.16994673934147345,\n",
       " 0.16323738118861,\n",
       " 0.16323738118861,\n",
       " 0.16323738118861,\n",
       " 0.6952555278320091,\n",
       " 0.7137050585355463,\n",
       " 0.5736318436542044,\n",
       " 0.6890812692585625,\n",
       " 0.16323738118861,\n",
       " 0.6982595567689206,\n",
       " 0.7488865215772186,\n",
       " 0.6974611582552831,\n",
       " 0.16385050843843915,\n",
       " 0.7443017724682829,\n",
       " 0.18323890100534534,\n",
       " 0.16323738118861,\n",
       " 0.7157416308325899,\n",
       " 0.17482694929110465,\n",
       " 0.659856302145893,\n",
       " 0.16222399507692659,\n",
       " 0.16323738118861,\n",
       " 0.16304445525505942,\n",
       " 0.16431861968790168]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model_1(X_train.drop(['a', 'b', 'TM_A', 'TM_B'],1), \n",
    "             y_train, X_test.drop(['a', 'b', 'TM_A', 'TM_B'], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed fold 1 of 10\n",
      "completed fold 2 of 10\n",
      "completed fold 3 of 10\n",
      "completed fold 4 of 10\n",
      "completed fold 5 of 10\n",
      "completed fold 6 of 10\n",
      "completed fold 7 of 10\n",
      "completed fold 8 of 10\n",
      "completed fold 9 of 10\n",
      "completed fold 10 of 10\n"
     ]
    }
   ],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# Stratified K-Folds cross-validator\n",
    "meta_training = pd.DataFrame()\n",
    "\n",
    "stratified_kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "fold = 1\n",
    "for train_index, test_index in stratified_kfold.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    oof_pred = X_test[['TM_A', 'TM_B']]\n",
    "    \n",
    "    oof_pred['predict_proba'] = base_model_1(X_train.drop(['a', 'b', 'TM_A', 'TM_B'], 1),\n",
    "                                      y_train,\n",
    "                                      X_test.drop(['a', 'b', 'TM_A', 'TM_B'], 1))\n",
    "\n",
    "#     oof_pred['siamese_sim'] = base_model_2(X_train[['name_a', 'name_b']],\n",
    "#                                       y_train,\n",
    "#                                       X_test[['name_a', 'name_b']])\n",
    "    \n",
    "    oof_pred['target'] = y_test.tolist()\n",
    "    \n",
    "    print('completed fold {} of 10'.format(fold))\n",
    "    fold += 1\n",
    "\n",
    "    meta_training = meta_training.append(oof_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TM_A</th>\n",
       "      <th>TM_B</th>\n",
       "      <th>predict_proba</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>upgooats</td>\n",
       "      <td>hardcore</td>\n",
       "      <td>0.169340</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>dialux</td>\n",
       "      <td>dial</td>\n",
       "      <td>0.677585</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>imperialreserva</td>\n",
       "      <td>imperial</td>\n",
       "      <td>0.732702</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>edenpure</td>\n",
       "      <td>edenaesthetics</td>\n",
       "      <td>0.645059</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>eezeevet</td>\n",
       "      <td>easipetcareltd</td>\n",
       "      <td>0.240520</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>naturefarmfood</td>\n",
       "      <td>canvaslifestyle</td>\n",
       "      <td>0.169525</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>camelactiv</td>\n",
       "      <td>camelcapa</td>\n",
       "      <td>0.701682</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>swisse</td>\n",
       "      <td>swisslifeforever</td>\n",
       "      <td>0.681933</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>bodrum</td>\n",
       "      <td>didim</td>\n",
       "      <td>0.201698</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>naturefarmfood</td>\n",
       "      <td>farmnature</td>\n",
       "      <td>0.637390</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>flossbone</td>\n",
       "      <td>tommy</td>\n",
       "      <td>0.169340</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>pepespiripiri</td>\n",
       "      <td>horizonrisksolutions</td>\n",
       "      <td>0.168182</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>stonerez</td>\n",
       "      <td>stonliner</td>\n",
       "      <td>0.709566</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>tatadoo</td>\n",
       "      <td>yourmaternityshop</td>\n",
       "      <td>0.164620</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>wecasablanca</td>\n",
       "      <td>cresco</td>\n",
       "      <td>0.169198</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>logicslide</td>\n",
       "      <td>magnavoc</td>\n",
       "      <td>0.169198</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>savvy</td>\n",
       "      <td>uberjet</td>\n",
       "      <td>0.170487</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>dragon</td>\n",
       "      <td>galaxy</td>\n",
       "      <td>0.173228</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>britishgas</td>\n",
       "      <td>thescienceofstoke</td>\n",
       "      <td>0.169388</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>glenfiddich</td>\n",
       "      <td>glenfield</td>\n",
       "      <td>0.708009</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                TM_A                  TM_B  predict_proba  target\n",
       "57          upgooats              hardcore       0.169340       0\n",
       "128           dialux                  dial       0.677585       1\n",
       "235  imperialreserva              imperial       0.732702       1\n",
       "71          edenpure        edenaesthetics       0.645059       1\n",
       "293         eezeevet        easipetcareltd       0.240520       0\n",
       "69    naturefarmfood       canvaslifestyle       0.169525       0\n",
       "34        camelactiv             camelcapa       0.701682       1\n",
       "46            swisse      swisslifeforever       0.681933       1\n",
       "141           bodrum                 didim       0.201698       1\n",
       "95    naturefarmfood            farmnature       0.637390       1\n",
       "189        flossbone                 tommy       0.169340       0\n",
       "285    pepespiripiri  horizonrisksolutions       0.168182       0\n",
       "322         stonerez             stonliner       0.709566       0\n",
       "98           tatadoo     yourmaternityshop       0.164620       0\n",
       "36      wecasablanca                cresco       0.169198       0\n",
       "205       logicslide              magnavoc       0.169198       0\n",
       "13             savvy               uberjet       0.170487       0\n",
       "118           dragon                galaxy       0.173228       0\n",
       "221       britishgas     thescienceofstoke       0.169388       0\n",
       "110      glenfiddich             glenfield       0.708009       1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_training.sample(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta-Model: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c55300b03784f2d9d1f2880c5b13531",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=657.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "067ee4a5db8c4b10953503623bdca4f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=657.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "743bdc1a1eba4a138102dd719c25e980",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=657.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "297d231f8b8942399bc124c92c9dcd3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=657.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f31c1c9d5a9c4a1dbfce7a5b941f0e4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=657.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49e4b1f939224f75b32e0b51dabd4127",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=657.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c0e192386d3476ab8cc54f1b8d8a908",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=657.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be59dcf319e14813aacde9f0978ebfa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=657.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9964f351e5e145209f26f1ae29049f1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=657.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dac17c143d0748b5b1ae56a6d85adb5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=657.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "118afccbd68448edb7bd91ce3c65e007",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=657.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "211cdd7c74b7400fb76b04e6067aec18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=657.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52af95edf323441d84773b23b0aee5a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=657.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e13434d249c94e14bbae30ba5e5f3002",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=657.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8adbcddd9a4415c903d62aaaa31c8aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=657.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d69d1b18546943a2a2d5a00192f1ea23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=657.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd12f5caa95640e096fab3ca892d22da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=657.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df=featurize(meta_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>predict_proba</th>\n",
       "      <th>target</th>\n",
       "      <th>TM_A</th>\n",
       "      <th>TM_B</th>\n",
       "      <th>partial</th>\n",
       "      <th>tkn_sort</th>\n",
       "      <th>tkn_set</th>\n",
       "      <th>levenshtein</th>\n",
       "      <th>...</th>\n",
       "      <th>mra</th>\n",
       "      <th>editex</th>\n",
       "      <th>saps</th>\n",
       "      <th>flexmetric</th>\n",
       "      <th>jaro</th>\n",
       "      <th>higueramico</th>\n",
       "      <th>sift4</th>\n",
       "      <th>eudex</th>\n",
       "      <th>aline</th>\n",
       "      <th>phoneticeditdistance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>lafrancaiseinvestingtogether</td>\n",
       "      <td>thew</td>\n",
       "      <td>0.264621</td>\n",
       "      <td>0</td>\n",
       "      <td>lafrancaiseinvestingtogether</td>\n",
       "      <td>thew</td>\n",
       "      <td>75</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.232143</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.626471</td>\n",
       "      <td>0.111842</td>\n",
       "      <td>0.130184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>londonhairlab</td>\n",
       "      <td>gameofstones</td>\n",
       "      <td>0.168905</td>\n",
       "      <td>0</td>\n",
       "      <td>londonhairlab</td>\n",
       "      <td>gameofstones</td>\n",
       "      <td>25</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.146154</td>\n",
       "      <td>0.493590</td>\n",
       "      <td>0.110122</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.765686</td>\n",
       "      <td>0.254930</td>\n",
       "      <td>0.720844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>blephaclean</td>\n",
       "      <td>willowtreegin</td>\n",
       "      <td>0.185320</td>\n",
       "      <td>0</td>\n",
       "      <td>blephaclean</td>\n",
       "      <td>willowtreegin</td>\n",
       "      <td>36</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.392308</td>\n",
       "      <td>0.557110</td>\n",
       "      <td>0.224359</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.832843</td>\n",
       "      <td>0.406349</td>\n",
       "      <td>0.648883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>ofo</td>\n",
       "      <td>ovo</td>\n",
       "      <td>0.674461</td>\n",
       "      <td>1</td>\n",
       "      <td>ofo</td>\n",
       "      <td>ovo</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.999020</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.989247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>woodystout</td>\n",
       "      <td>woodybrownale</td>\n",
       "      <td>0.603822</td>\n",
       "      <td>1</td>\n",
       "      <td>woodystout</td>\n",
       "      <td>woodybrownale</td>\n",
       "      <td>60</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.687179</td>\n",
       "      <td>0.441142</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.835294</td>\n",
       "      <td>0.485714</td>\n",
       "      <td>0.727047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>micron</td>\n",
       "      <td>therealpetfoodcompany</td>\n",
       "      <td>0.167358</td>\n",
       "      <td>0</td>\n",
       "      <td>micron</td>\n",
       "      <td>therealpetfoodcompany</td>\n",
       "      <td>50</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.680392</td>\n",
       "      <td>0.182883</td>\n",
       "      <td>0.269585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>theuniversityoflaw</td>\n",
       "      <td>ulaw</td>\n",
       "      <td>0.334822</td>\n",
       "      <td>1</td>\n",
       "      <td>theuniversityoflaw</td>\n",
       "      <td>ulaw</td>\n",
       "      <td>75</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.383333</td>\n",
       "      <td>0.435185</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.563235</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>vype</td>\n",
       "      <td>veype</td>\n",
       "      <td>0.692897</td>\n",
       "      <td>1</td>\n",
       "      <td>vype</td>\n",
       "      <td>veype</td>\n",
       "      <td>75</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.998039</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>grey</td>\n",
       "      <td>maternityyours</td>\n",
       "      <td>0.166972</td>\n",
       "      <td>0</td>\n",
       "      <td>grey</td>\n",
       "      <td>maternityyours</td>\n",
       "      <td>25</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.543651</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.710294</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.268433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>eris</td>\n",
       "      <td>gameofstones</td>\n",
       "      <td>0.169777</td>\n",
       "      <td>0</td>\n",
       "      <td>eris</td>\n",
       "      <td>gameofstones</td>\n",
       "      <td>50</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.295833</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.649020</td>\n",
       "      <td>0.167187</td>\n",
       "      <td>0.327957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>elysium</td>\n",
       "      <td>booboo</td>\n",
       "      <td>0.164620</td>\n",
       "      <td>0</td>\n",
       "      <td>elysium</td>\n",
       "      <td>booboo</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.128571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.596569</td>\n",
       "      <td>0.327273</td>\n",
       "      <td>0.672811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>aadvantage</td>\n",
       "      <td>advantageholidaysbyadvantage</td>\n",
       "      <td>0.633665</td>\n",
       "      <td>1</td>\n",
       "      <td>aadvantage</td>\n",
       "      <td>advantageholidaysbyadvantage</td>\n",
       "      <td>90</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.410714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.462500</td>\n",
       "      <td>0.652381</td>\n",
       "      <td>0.001797</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.815196</td>\n",
       "      <td>0.340278</td>\n",
       "      <td>0.357143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>tlclive</td>\n",
       "      <td>tlctraining</td>\n",
       "      <td>0.589134</td>\n",
       "      <td>1</td>\n",
       "      <td>tlclive</td>\n",
       "      <td>tlctraining</td>\n",
       "      <td>57</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.436364</td>\n",
       "      <td>0.645022</td>\n",
       "      <td>0.300253</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.847549</td>\n",
       "      <td>0.458462</td>\n",
       "      <td>0.601173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>pureipr</td>\n",
       "      <td>hamiltoninches</td>\n",
       "      <td>0.167661</td>\n",
       "      <td>0</td>\n",
       "      <td>pureipr</td>\n",
       "      <td>hamiltoninches</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.389286</td>\n",
       "      <td>0.404762</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.716176</td>\n",
       "      <td>0.169231</td>\n",
       "      <td>0.453917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>lucedellavite</td>\n",
       "      <td>arcatadiluce</td>\n",
       "      <td>0.360706</td>\n",
       "      <td>0</td>\n",
       "      <td>lucedellavite</td>\n",
       "      <td>arcatadiluce</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>0.407692</td>\n",
       "      <td>0.542735</td>\n",
       "      <td>0.246886</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.674020</td>\n",
       "      <td>0.501493</td>\n",
       "      <td>0.775434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>houseofsilk</td>\n",
       "      <td>silkcut</td>\n",
       "      <td>0.639971</td>\n",
       "      <td>1</td>\n",
       "      <td>houseofsilk</td>\n",
       "      <td>silkcut</td>\n",
       "      <td>57</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.322511</td>\n",
       "      <td>0.109610</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.851961</td>\n",
       "      <td>0.442105</td>\n",
       "      <td>0.533724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>dank</td>\n",
       "      <td>dankvapes</td>\n",
       "      <td>0.756866</td>\n",
       "      <td>1</td>\n",
       "      <td>dank</td>\n",
       "      <td>dankvapes</td>\n",
       "      <td>100</td>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.505556</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.254365</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.935294</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>next</td>\n",
       "      <td>nextdealshop</td>\n",
       "      <td>0.682281</td>\n",
       "      <td>1</td>\n",
       "      <td>next</td>\n",
       "      <td>nextdealshop</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.479167</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.926471</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>moscany</td>\n",
       "      <td>toskani</td>\n",
       "      <td>0.562538</td>\n",
       "      <td>1</td>\n",
       "      <td>moscany</td>\n",
       "      <td>toskani</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.741176</td>\n",
       "      <td>0.751351</td>\n",
       "      <td>0.953917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>boost</td>\n",
       "      <td>boostshot</td>\n",
       "      <td>0.738442</td>\n",
       "      <td>1</td>\n",
       "      <td>boost</td>\n",
       "      <td>boostshot</td>\n",
       "      <td>100</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>0.454365</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.925490</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                a                             b  \\\n",
       "243  lafrancaiseinvestingtogether                          thew   \n",
       "222                 londonhairlab                  gameofstones   \n",
       "125                   blephaclean                 willowtreegin   \n",
       "140                           ofo                           ovo   \n",
       "7                      woodystout                 woodybrownale   \n",
       "279                        micron         therealpetfoodcompany   \n",
       "31             theuniversityoflaw                          ulaw   \n",
       "276                          vype                         veype   \n",
       "85                           grey                maternityyours   \n",
       "281                          eris                  gameofstones   \n",
       "199                       elysium                        booboo   \n",
       "188                    aadvantage  advantageholidaysbyadvantage   \n",
       "66                        tlclive                   tlctraining   \n",
       "16                        pureipr                hamiltoninches   \n",
       "290                 lucedellavite                  arcatadiluce   \n",
       "69                    houseofsilk                       silkcut   \n",
       "52                           dank                     dankvapes   \n",
       "113                          next                  nextdealshop   \n",
       "178                       moscany                       toskani   \n",
       "54                          boost                     boostshot   \n",
       "\n",
       "     predict_proba  target                          TM_A  \\\n",
       "243       0.264621       0  lafrancaiseinvestingtogether   \n",
       "222       0.168905       0                 londonhairlab   \n",
       "125       0.185320       0                   blephaclean   \n",
       "140       0.674461       1                           ofo   \n",
       "7         0.603822       1                    woodystout   \n",
       "279       0.167358       0                        micron   \n",
       "31        0.334822       1            theuniversityoflaw   \n",
       "276       0.692897       1                          vype   \n",
       "85        0.166972       0                          grey   \n",
       "281       0.169777       0                          eris   \n",
       "199       0.164620       0                       elysium   \n",
       "188       0.633665       1                    aadvantage   \n",
       "66        0.589134       1                       tlclive   \n",
       "16        0.167661       0                       pureipr   \n",
       "290       0.360706       0                 lucedellavite   \n",
       "69        0.639971       1                   houseofsilk   \n",
       "52        0.756866       1                          dank   \n",
       "113       0.682281       1                          next   \n",
       "178       0.562538       1                       moscany   \n",
       "54        0.738442       1                         boost   \n",
       "\n",
       "                             TM_B  partial  tkn_sort  tkn_set  levenshtein  \\\n",
       "243                          thew       75        19       19     0.714286   \n",
       "222                  gameofstones       25        24       24     0.342857   \n",
       "125                 willowtreegin       36        33       33     0.285714   \n",
       "140                           ovo       67        67       67     0.028571   \n",
       "7                   woodybrownale       60        52       52     0.200000   \n",
       "279         therealpetfoodcompany       50        22       22     0.514286   \n",
       "31                           ulaw       75        36       36     0.400000   \n",
       "276                         veype       75        89       89     0.028571   \n",
       "85                 maternityyours       25        22       22     0.342857   \n",
       "281                  gameofstones       50        25       25     0.285714   \n",
       "199                        booboo        0         0        0     0.200000   \n",
       "188  advantageholidaysbyadvantage       90        53       53     0.514286   \n",
       "66                    tlctraining       57        44       44     0.200000   \n",
       "16                 hamiltoninches       14        10       10     0.371429   \n",
       "290                  arcatadiluce       33        32       32     0.314286   \n",
       "69                        silkcut       57        44       44     0.285714   \n",
       "52                      dankvapes      100        62       62     0.142857   \n",
       "113                  nextdealshop      100        50       50     0.228571   \n",
       "178                       toskani       57        57       57     0.085714   \n",
       "54                      boostshot      100        71       71     0.114286   \n",
       "\n",
       "     ...       mra    editex      saps  flexmetric      jaro  higueramico  \\\n",
       "243  ...  0.000000  0.142857  0.000000    0.232143  0.428571     0.000000   \n",
       "222  ...  0.000000  0.269231  0.000000    0.146154  0.493590     0.110122   \n",
       "125  ...  0.333333  0.423077  0.000000    0.392308  0.557110     0.224359   \n",
       "140  ...  0.833333  0.833333  0.384615    0.966667  0.777778     0.666667   \n",
       "7    ...  0.500000  0.538462  0.105263    0.550000  0.687179     0.441142   \n",
       "279  ...  0.000000  0.238095  0.000000    0.371429  0.476190     0.000000   \n",
       "31   ...  0.000000  0.277778  0.000000    0.383333  0.435185     0.000000   \n",
       "276  ...  1.000000  0.800000  0.866667    0.900000  0.933333     0.800000   \n",
       "85   ...  0.000000  0.321429  0.000000    0.357143  0.543651     0.000000   \n",
       "281  ...  0.000000  0.250000  0.000000    0.295833  0.555556     0.000000   \n",
       "199  ...  0.000000  0.214286  0.000000    0.128571  0.000000     0.000000   \n",
       "188  ...  1.000000  0.410714  0.000000    0.462500  0.652381     0.001797   \n",
       "66   ...  0.500000  0.454545  0.130435    0.436364  0.645022     0.300253   \n",
       "16   ...  0.000000  0.250000  0.000000    0.389286  0.404762     0.000000   \n",
       "290  ...  0.000000  0.423077  0.046512    0.407692  0.542735     0.246886   \n",
       "69   ...  0.000000  0.272727  0.000000    0.318182  0.322511     0.109610   \n",
       "52   ...  0.000000  0.444444  0.172414    0.505556  0.814815     0.254365   \n",
       "113  ...  0.000000  0.458333  0.000000    0.479167  0.777778     0.000000   \n",
       "178  ...  0.500000  0.714286  0.181818    0.828571  0.714286     0.571429   \n",
       "54   ...  0.000000  0.611111  0.241379    0.688889  0.851852     0.454365   \n",
       "\n",
       "        sift4     eudex     aline  phoneticeditdistance  \n",
       "243  0.000000  0.626471  0.111842              0.130184  \n",
       "222  0.153846  0.765686  0.254930              0.720844  \n",
       "125  0.307692  0.832843  0.406349              0.648883  \n",
       "140  0.666667  0.999020  0.769231              0.989247  \n",
       "7    0.461538  0.835294  0.485714              0.727047  \n",
       "279  0.047619  0.680392  0.182883              0.269585  \n",
       "31   0.055556  0.563235  0.150000              0.222222  \n",
       "276  0.800000  0.998039  0.934783              0.800000  \n",
       "85   0.071429  0.710294  0.150000              0.268433  \n",
       "281  0.166667  0.649020  0.167187              0.327957  \n",
       "199  0.000000  0.596569  0.327273              0.672811  \n",
       "188  0.321429  0.815196  0.340278              0.357143  \n",
       "66   0.363636  0.847549  0.458462              0.601173  \n",
       "16   0.071429  0.716176  0.169231              0.453917  \n",
       "290  0.384615  0.674020  0.501493              0.775434  \n",
       "69   0.090909  0.851961  0.442105              0.533724  \n",
       "52   0.444444  0.935294  0.470588              0.444444  \n",
       "113  0.333333  0.926471  0.352941              0.333333  \n",
       "178  0.571429  0.741176  0.751351              0.953917  \n",
       "54   0.555556  0.925490  0.529412              0.555556  \n",
       "\n",
       "[20 rows x 31 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[32  5]\n",
      " [ 4 24]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.86      0.88        37\n",
      "           1       0.83      0.86      0.84        28\n",
      "\n",
      "    accuracy                           0.86        65\n",
      "   macro avg       0.86      0.86      0.86        65\n",
      "weighted avg       0.86      0.86      0.86        65\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb_clf2 = GradientBoostingClassifier(learning_rate=0.01, \n",
    "        max_depth=3, max_features=0.5,\n",
    "        min_samples_leaf=10, min_samples_split=3, \n",
    "        n_estimators=100, subsample=0.9500000000000001)\n",
    "gb_clf2.fit(X_train.drop(['a', 'b', 'TM_A', 'TM_B'], 1), y_train)\n",
    "predictions = gb_clf2.predict(X_test.drop(['a', 'b', 'TM_A', 'TM_B'], 1))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_confusion.to_csv('TM_GBC_Confusion_matris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc curve and auc\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.6, 0.3, 'AUC=0.926')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(7,7))\n",
    "baseline_probs = [0 for _ in range(len(y_test))]\n",
    "\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = gb_clf2.predict_proba(X_test.drop(['a', 'b', 'TM_A', 'TM_B'], 1))\n",
    "probs = probs[:, 1]\n",
    "\n",
    "# calculate scores\n",
    "baseline_auc = roc_auc_score(y_test, baseline_probs)\n",
    "auc = roc_auc_score(y_test, probs)\n",
    "auc = ('AUC=%.3f' % (auc))\n",
    "\n",
    "# calculate roc curves\n",
    "baseline_fpr, baseline_tpr, _ = roc_curve(y_test, baseline_probs)\n",
    "fpr, tpr, _ = roc_curve(y_test, probs)\n",
    "\n",
    "# plot the roc curve for the model\n",
    "ax.plot(baseline_fpr, baseline_tpr, color='gray')\n",
    "ax.plot(fpr, tpr, marker='.', color='black')\n",
    "\n",
    "# axis labels\n",
    "ax.set_xlabel('False Positive Rate',fontsize=12)\n",
    "ax.set_ylabel('True Positive Rate',fontsize=12)\n",
    "ax.set_title('Receiver Operating Characteristic', fontsize=16)\n",
    "plt.text(.6, .3, auc, fontsize=13)\n",
    "\n",
    "# plt.savefig('TM_GBC_ROC.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "corr = df.corr()\n",
    "sns.heatmap(corr, xticklabels=corr.columns.values,\n",
    "            yticklabels=corr.columns.values, annot = True,\n",
    "            cmap=\"YlGnBu_r\")\n",
    "heat_map=plt.gcf()\n",
    "heat_map.set_size_inches(20,15)\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search   \n",
    "\n",
    "Hyperparameter tuning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [col for col in df.columns if col not in ['a', 'b', 'TM_A', 'TM_B', 'target', 'predict_proba']]\n",
    "comb2 = list(combinations(cols, 2))\n",
    "comb3 = list(combinations(cols, 3))\n",
    "colgrid = [(col,)for col in cols]+comb2+comb3\n",
    "\n",
    "\n",
    "colgrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df, df.target, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression()\n",
    "grid_clf = GridSearchCV(clf, param_grid = {'C':np.logspace(-4, 4, 20)}, scoring = 'precision', verbose=0)\n",
    "\n",
    "scores = []\n",
    "for cols in colgrid:\n",
    "    grid_clf.fit(X_train[['predict_proba']+list(cols)], y_train)\n",
    "    y_pred = grid_clf.predict(X_val[['predict_proba']+list(cols)])\n",
    "    tn, fp, fn, tp = confusion_matrix(y_val, y_pred).ravel()\n",
    "    scores.append([str(cols), tn, fp, fn, tp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df.columns = ['features', 'tn', 'fp', 'fn', 'tp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df['error'] = scores_df['fp'] + scores_df['fn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = scores_df.sort_values(['error', 'fp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df, df.target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cols = ['predict_proba', 'tkn_set', 'iterativesubstring', 'strcmp95']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression()\n",
    "grid_clf = GridSearchCV(clf, param_grid = {'C':np.logspace(-4, 4, 20)}, scoring='precision')\n",
    "grid_clf.fit(X_train[selected_cols], y_train)\n",
    "y_pred = grid_clf.predict(X_test[selected_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_test, y_pred):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    conf_matrix = pd.DataFrame(data=cm, columns=['Predicted: 0', 'Predicted: 1'], index=['Actual: 0', 'Actual: 1'])\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc curve and auc\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(7,7))\n",
    "baseline_probs = [0 for _ in range(len(y_test))]\n",
    "\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = grid_clf.predict_proba(X_test[selected_cols])\n",
    "probs = probs[:, 1]\n",
    "\n",
    "# calculate scores\n",
    "baseline_auc = roc_auc_score(y_test, baseline_probs)\n",
    "auc = roc_auc_score(y_test, probs)\n",
    "auc = ('AUC=%.3f' % (auc))\n",
    "\n",
    "# calculate roc curves\n",
    "baseline_fpr, baseline_tpr, _ = roc_curve(y_test, baseline_probs)\n",
    "fpr, tpr, _ = roc_curve(y_test, probs)\n",
    "\n",
    "# plot the roc curve for the model\n",
    "ax.plot(baseline_fpr, baseline_tpr, color='gray')\n",
    "ax.plot(fpr, tpr, marker='.', color='black')\n",
    "\n",
    "# axis labels\n",
    "ax.set_xlabel('False Positive Rate',fontsize=12)\n",
    "ax.set_ylabel('True Positive Rate',fontsize=12)\n",
    "ax.set_title('Receiver Operating Characteristic', fontsize=16)\n",
    "plt.text(.6, .3, auc, fontsize=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Models and Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_1 = base_model_1(X.drop(['a', 'b', 'TM_A', 'TM_B'], 1), y, X_test=None, export=True)\n",
    "joblib.dump(base_1, filename='Data.nosync/TM_Gradient_boost_base_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model_2(X[['name_a', 'name_b']], y, X_test=None, export=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(grid_clf.best_estimator_, filename='Data.nosync/TM_meta_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TPOT AutoML Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpot import TPOTRegressor\n",
    "\n",
    "pipeline_optimizer = TPOTRegressor(\n",
    "        scoring = 'f1', \n",
    "        generations=100,\n",
    "        verbosity=2,\n",
    "        n_jobs=-1   # Utilizes all available CPU cores\n",
    "        ) \n",
    "pipeline_optimizer.fit(X_train.drop(['a', 'b', 'TM_A', 'TM_B'],1), y_train)\n",
    "\n",
    "exported_pipeline = make_pipeline("
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
