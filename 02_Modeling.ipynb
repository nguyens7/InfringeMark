{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TM_A</th>\n",
       "      <th>TM_B</th>\n",
       "      <th>Decision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Simoniz</td>\n",
       "      <td>Permanize</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Magnavoc</td>\n",
       "      <td>Multivox</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Zirco</td>\n",
       "      <td>Cozirc</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Platinum Puff</td>\n",
       "      <td>Platinum Plus</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Maternity Yours</td>\n",
       "      <td>Your Maternity Shop</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>Lilton</td>\n",
       "      <td>Wilton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>Nutricia</td>\n",
       "      <td>Nutritea</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>Glenreidh</td>\n",
       "      <td>An Reidhe</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>No Gunk No Junk</td>\n",
       "      <td>No Gunk Just Funk</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>e-Relief</td>\n",
       "      <td>LIGHT RELIEF</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>357 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                TM_A                 TM_B  Decision\n",
       "0            Simoniz            Permanize         1\n",
       "1           Magnavoc             Multivox         1\n",
       "2              Zirco               Cozirc         1\n",
       "3      Platinum Puff        Platinum Plus         1\n",
       "4    Maternity Yours  Your Maternity Shop         1\n",
       "..               ...                  ...       ...\n",
       "352           Lilton               Wilton         0\n",
       "353         Nutricia             Nutritea         0\n",
       "354        Glenreidh            An Reidhe         0\n",
       "355  No Gunk No Junk    No Gunk Just Funk         0\n",
       "356         e-Relief         LIGHT RELIEF         0\n",
       "\n",
       "[357 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cases = pd.read_csv('Data.nosync/Similar_TM.csv')\n",
    "cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unidecode\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "from abydos.distance import (IterativeSubString, BISIM, DiscountedLevenshtein, Prefix, LCSstr, MLIPNS, Strcmp95,\n",
    "MRA, Editex, SAPS, FlexMetric, JaroWinkler, HigueraMico, Sift4, Eudex, ALINE, PhoneticEditDistance)\n",
    "\n",
    "from abydos.phonetic import PSHPSoundexFirst, Ainsworth\n",
    "pshp_soundex_first = PSHPSoundexFirst()\n",
    "pe = Ainsworth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "iss = IterativeSubString()\n",
    "bisim = BISIM()\n",
    "dlev = DiscountedLevenshtein()\n",
    "prefix = Prefix()\n",
    "lcs = LCSstr()\n",
    "mlipns = MLIPNS()\n",
    "strcmp95 = Strcmp95()\n",
    "mra = MRA()\n",
    "editex = Editex()\n",
    "saps = SAPS()\n",
    "flexmetric = FlexMetric()\n",
    "jaro = JaroWinkler(mode='Jaro')\n",
    "higuera_mico = HigueraMico()\n",
    "sift4 = Sift4()\n",
    "eudex = Eudex()\n",
    "aline = ALINE()\n",
    "phonetic_edit = PhoneticEditDistance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "algos = [iss, bisim, dlev, prefix, lcs, mlipns, strcmp95, mra, editex, saps, flexmetric, jaro, higuera_mico, sift4, eudex,\n",
    "         aline, phonetic_edit]\n",
    "\n",
    "algo_names = ['iterativesubstring', 'bisim', 'discountedlevenshtein', 'prefix', 'lcsstr', 'mlipns', 'strcmp95', 'mra',\n",
    "              'editex', 'saps', 'flexmetric', 'jaro', 'higueramico', 'sift4', 'eudex', 'aline',\n",
    "              'phoneticeditdistance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abydos.phones import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_ipa(name_a, name_b):\n",
    "    feat1 = ipa_to_features(pe.encode(name_a))\n",
    "    feat2 = ipa_to_features(pe.encode(name_b))\n",
    "    score = sum(cmp_features(f1, f2) for f1, f2 in zip(feat1, feat2))/len(feat1)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def featurize(df):\n",
    "    if len(df.columns)==3:\n",
    "        df.columns=['a', 'b', 'target']\n",
    "    elif len(df.columns)==2:\n",
    "        df.columns=['a', 'b']\n",
    "    else:\n",
    "        df = df.rename(columns={df.columns[0]: 'a', df.columns[1]: 'b' })\n",
    "        \n",
    "    df['TM_A'] = df.apply(lambda row: re.sub(\n",
    "        '[^a-zA-Z]+', '', unidecode.unidecode(row['a']).lower()), axis=1)\n",
    "    df['TM_B'] = df.apply(lambda row: re.sub(\n",
    "        '[^a-zA-Z]+', '', unidecode.unidecode(row['b']).lower()), axis=1)\n",
    "    \n",
    "\n",
    "    df['partial'] = df.apply(lambda row: fuzz.partial_ratio(row.TM_A,row.TM_B), axis=1)\n",
    "    df['tkn_sort'] = df.apply(lambda row: fuzz.token_sort_ratio(row.TM_A,row.TM_B), axis=1)\n",
    "    df['tkn_set'] = df.apply(lambda row: fuzz.token_set_ratio(row.TM_A,row.TM_B), axis=1)\n",
    "    \n",
    "    df['sum_ipa'] = df.apply(lambda row: sum_ipa(row.TM_A,row.TM_B), axis=1)\n",
    "    \n",
    "    df['pshp_soundex_first'] = df.apply(\n",
    "        lambda row: 1 if pshp_soundex_first.encode(row.TM_A)==pshp_soundex_first.encode(row.TM_B) else 0, axis=1)\n",
    "    \n",
    "    for i, algo in enumerate(algos):\n",
    "            df[algo_names[i]] = df.progress_apply(lambda row: algo.sim(row.TM_A, row.TM_B), axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from itertools import combinations\n",
    "import random\n",
    "random.seed(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TM_A</th>\n",
       "      <th>TM_B</th>\n",
       "      <th>Decision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Zirco</td>\n",
       "      <td>Cozirc</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    TM_A    TM_B  Decision\n",
       "2  Zirco  Cozirc         1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftest=cases.loc[[2]]\n",
    "dftest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seannguyen/opt/anaconda3/lib/python3.8/site-packages/tqdm/std.py:668: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n",
      "100%|██████████| 357/357 [00:00<00:00, 14983.55it/s]\n",
      "100%|██████████| 357/357 [00:00<00:00, 4844.95it/s]\n",
      "100%|██████████| 357/357 [00:00<00:00, 3555.78it/s]\n",
      "100%|██████████| 357/357 [00:00<00:00, 22298.50it/s]\n",
      "100%|██████████| 357/357 [00:00<00:00, 12395.42it/s]\n",
      "100%|██████████| 357/357 [00:00<00:00, 23828.24it/s]\n",
      "100%|██████████| 357/357 [00:00<00:00, 13957.30it/s]\n",
      "100%|██████████| 357/357 [00:00<00:00, 12443.42it/s]\n",
      "100%|██████████| 357/357 [00:00<00:00, 2149.89it/s]\n",
      "100%|██████████| 357/357 [00:00<00:00, 3237.89it/s]\n",
      "100%|██████████| 357/357 [00:00<00:00, 2458.19it/s]\n",
      "100%|██████████| 357/357 [00:00<00:00, 13097.57it/s]\n",
      "100%|██████████| 357/357 [00:01<00:00, 248.76it/s]\n",
      "100%|██████████| 357/357 [00:00<00:00, 16616.91it/s]\n",
      "100%|██████████| 357/357 [00:00<00:00, 10659.92it/s]\n",
      "100%|██████████| 357/357 [00:01<00:00, 195.11it/s]\n",
      "100%|██████████| 357/357 [00:00<00:00, 1130.52it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>target</th>\n",
       "      <th>TM_A</th>\n",
       "      <th>TM_B</th>\n",
       "      <th>partial</th>\n",
       "      <th>tkn_sort</th>\n",
       "      <th>tkn_set</th>\n",
       "      <th>sum_ipa</th>\n",
       "      <th>pshp_soundex_first</th>\n",
       "      <th>...</th>\n",
       "      <th>mra</th>\n",
       "      <th>editex</th>\n",
       "      <th>saps</th>\n",
       "      <th>flexmetric</th>\n",
       "      <th>jaro</th>\n",
       "      <th>higueramico</th>\n",
       "      <th>sift4</th>\n",
       "      <th>eudex</th>\n",
       "      <th>aline</th>\n",
       "      <th>phoneticeditdistance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Simoniz</td>\n",
       "      <td>Permanize</td>\n",
       "      <td>1</td>\n",
       "      <td>simoniz</td>\n",
       "      <td>permanize</td>\n",
       "      <td>57</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>0.658986</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.671958</td>\n",
       "      <td>0.430556</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.654902</td>\n",
       "      <td>0.602128</td>\n",
       "      <td>0.727599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Magnavoc</td>\n",
       "      <td>Multivox</td>\n",
       "      <td>1</td>\n",
       "      <td>magnavoc</td>\n",
       "      <td>multivox</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>0.691532</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.897177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Zirco</td>\n",
       "      <td>Cozirc</td>\n",
       "      <td>1</td>\n",
       "      <td>zirco</td>\n",
       "      <td>cozirc</td>\n",
       "      <td>89</td>\n",
       "      <td>73</td>\n",
       "      <td>73</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>0.547619</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.786275</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.634409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Platinum Puff</td>\n",
       "      <td>Platinum Plus</td>\n",
       "      <td>1</td>\n",
       "      <td>platinumpuff</td>\n",
       "      <td>platinumplus</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>0.895161</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.873529</td>\n",
       "      <td>0.913978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Maternity Yours</td>\n",
       "      <td>Your Maternity Shop</td>\n",
       "      <td>1</td>\n",
       "      <td>maternityyours</td>\n",
       "      <td>yourmaternityshop</td>\n",
       "      <td>74</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>0.743176</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.319149</td>\n",
       "      <td>0.538235</td>\n",
       "      <td>0.687675</td>\n",
       "      <td>0.490372</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.463725</td>\n",
       "      <td>0.589655</td>\n",
       "      <td>0.646110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>Lilton</td>\n",
       "      <td>Wilton</td>\n",
       "      <td>0</td>\n",
       "      <td>lilton</td>\n",
       "      <td>wilton</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>0.943548</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.943548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>Nutricia</td>\n",
       "      <td>Nutritea</td>\n",
       "      <td>0</td>\n",
       "      <td>nutricia</td>\n",
       "      <td>nutritea</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>0.874552</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.787500</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.997549</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.973790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>Glenreidh</td>\n",
       "      <td>An Reidhe</td>\n",
       "      <td>0</td>\n",
       "      <td>glenreidh</td>\n",
       "      <td>anreidhe</td>\n",
       "      <td>80</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>0.498208</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.741402</td>\n",
       "      <td>0.588889</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.784804</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.655914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>No Gunk No Junk</td>\n",
       "      <td>No Gunk Just Funk</td>\n",
       "      <td>0</td>\n",
       "      <td>nogunknojunk</td>\n",
       "      <td>nogunkjustfunk</td>\n",
       "      <td>67</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.469388</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.815873</td>\n",
       "      <td>0.637363</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.995588</td>\n",
       "      <td>0.713415</td>\n",
       "      <td>0.808756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>e-Relief</td>\n",
       "      <td>LIGHT RELIEF</td>\n",
       "      <td>0</td>\n",
       "      <td>erelief</td>\n",
       "      <td>lightrelief</td>\n",
       "      <td>86</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>0.629032</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.663636</td>\n",
       "      <td>0.689755</td>\n",
       "      <td>0.482071</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.775490</td>\n",
       "      <td>0.491803</td>\n",
       "      <td>0.633431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>357 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   a                    b  target            TM_A  \\\n",
       "0            Simoniz            Permanize       1         simoniz   \n",
       "1           Magnavoc             Multivox       1        magnavoc   \n",
       "2              Zirco               Cozirc       1           zirco   \n",
       "3      Platinum Puff        Platinum Plus       1    platinumpuff   \n",
       "4    Maternity Yours  Your Maternity Shop       1  maternityyours   \n",
       "..               ...                  ...     ...             ...   \n",
       "352           Lilton               Wilton       0          lilton   \n",
       "353         Nutricia             Nutritea       0        nutricia   \n",
       "354        Glenreidh            An Reidhe       0       glenreidh   \n",
       "355  No Gunk No Junk    No Gunk Just Funk       0    nogunknojunk   \n",
       "356         e-Relief         LIGHT RELIEF       0         erelief   \n",
       "\n",
       "                  TM_B  partial  tkn_sort  tkn_set   sum_ipa  \\\n",
       "0            permanize       57        50       50  0.658986   \n",
       "1             multivox       38        38       38  0.691532   \n",
       "2               cozirc       89        73       73  0.806452   \n",
       "3         platinumplus       83        83       83  0.895161   \n",
       "4    yourmaternityshop       74        65       65  0.743176   \n",
       "..                 ...      ...       ...      ...       ...   \n",
       "352             wilton       83        83       83  0.943548   \n",
       "353           nutritea       75        75       75  0.874552   \n",
       "354           anreidhe       80        71       71  0.498208   \n",
       "355     nogunkjustfunk       67        77       77  0.822581   \n",
       "356        lightrelief       86        67       67  0.629032   \n",
       "\n",
       "     pshp_soundex_first  ...       mra    editex      saps  flexmetric  \\\n",
       "0                     0  ...  0.666667  0.555556  0.137931    0.566667   \n",
       "1                     0  ...  0.500000  0.500000  0.304348    0.400000   \n",
       "2                     0  ...  0.833333  0.500000  0.428571    0.600000   \n",
       "3                     1  ...  0.500000  0.833333  0.666667    0.833333   \n",
       "4                     0  ...  0.000000  0.588235  0.319149    0.538235   \n",
       "..                  ...  ...       ...       ...       ...         ...   \n",
       "352                   0  ...  0.833333  0.833333  0.500000    0.833333   \n",
       "353                   1  ...  0.833333  0.812500  0.565217    0.787500   \n",
       "354                   0  ...  0.666667  0.666667  0.310345    0.666667   \n",
       "355                   1  ...  0.833333  0.678571  0.469388    0.700000   \n",
       "356                   0  ...  0.500000  0.636364  0.166667    0.663636   \n",
       "\n",
       "         jaro  higueramico     sift4     eudex     aline  phoneticeditdistance  \n",
       "0    0.671958     0.430556  0.444444  0.654902  0.602128              0.727599  \n",
       "1    0.583333     0.375000  0.375000  0.916667  0.545455              0.897177  \n",
       "2    0.822222     0.547619  0.666667  0.786275  0.705882              0.634409  \n",
       "3    0.888889     0.769231  0.833333  1.000000  0.873529              0.913978  \n",
       "4    0.687675     0.490372  0.588235  0.463725  0.589655              0.646110  \n",
       "..        ...          ...       ...       ...       ...                   ...  \n",
       "352  0.822222     0.833333  0.833333  0.866667  0.823529              0.943548  \n",
       "353  0.833333     0.750000  0.750000  0.997549  0.937500              0.973790  \n",
       "354  0.741402     0.588889  0.666667  0.784804  0.705882              0.655914  \n",
       "355  0.815873     0.637363  0.714286  0.995588  0.713415              0.808756  \n",
       "356  0.689755     0.482071  0.363636  0.775490  0.491803              0.633431  \n",
       "\n",
       "[357 rows x 27 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "df = featurize(cases)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export clean data to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('Data.nosync/TM_features.csv', index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.target\n",
    "X = df.drop(columns = 'target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TPOT AutoML pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpot import TPOTClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline_optimizer = TPOTClassifier(\n",
    "#         scoring = 'f1', \n",
    "#         generations=100,\n",
    "#         verbosity=2,\n",
    "#         n_jobs=-1   # Utilizes all available CPU cores\n",
    "#         ) \n",
    "# pipeline_optimizer.fit(X_train.drop(['a', 'b', 'TM_A', 'TM_B'],1), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pipeline_optimizer.score(X_test.drop(['a', 'b', 'TM_A', 'TM_B'], 1), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export TPOT pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline_optimizer.export('tpot_exported_calssifier_pipeline.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load TPOT pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>partial</th>\n",
       "      <th>tkn_sort</th>\n",
       "      <th>tkn_set</th>\n",
       "      <th>sum_ipa</th>\n",
       "      <th>pshp_soundex_first</th>\n",
       "      <th>iterativesubstring</th>\n",
       "      <th>bisim</th>\n",
       "      <th>discountedlevenshtein</th>\n",
       "      <th>prefix</th>\n",
       "      <th>...</th>\n",
       "      <th>mra</th>\n",
       "      <th>editex</th>\n",
       "      <th>saps</th>\n",
       "      <th>flexmetric</th>\n",
       "      <th>jaro</th>\n",
       "      <th>higueramico</th>\n",
       "      <th>sift4</th>\n",
       "      <th>eudex</th>\n",
       "      <th>aline</th>\n",
       "      <th>phoneticeditdistance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>0.658986</td>\n",
       "      <td>0</td>\n",
       "      <td>0.485480</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.383752</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.671958</td>\n",
       "      <td>0.430556</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.654902</td>\n",
       "      <td>0.602128</td>\n",
       "      <td>0.727599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>0.691532</td>\n",
       "      <td>0</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.366778</td>\n",
       "      <td>0.125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.897177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>73</td>\n",
       "      <td>73</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0</td>\n",
       "      <td>0.821263</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.495199</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>0.547619</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.786275</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.634409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>0.895161</td>\n",
       "      <td>1</td>\n",
       "      <td>0.884677</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.818487</td>\n",
       "      <td>0.750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.873529</td>\n",
       "      <td>0.913978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>0.743176</td>\n",
       "      <td>0</td>\n",
       "      <td>0.951613</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.472052</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.319149</td>\n",
       "      <td>0.538235</td>\n",
       "      <td>0.687675</td>\n",
       "      <td>0.490372</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.463725</td>\n",
       "      <td>0.589655</td>\n",
       "      <td>0.646110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>0.943548</td>\n",
       "      <td>0</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.796089</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.943548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>0.874552</td>\n",
       "      <td>1</td>\n",
       "      <td>0.804167</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.798406</td>\n",
       "      <td>0.625</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.787500</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.997549</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.973790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>0.498208</td>\n",
       "      <td>0</td>\n",
       "      <td>0.800858</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.510437</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.741402</td>\n",
       "      <td>0.588889</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.784804</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.655914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>1</td>\n",
       "      <td>0.852383</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.700763</td>\n",
       "      <td>0.500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.469388</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.815873</td>\n",
       "      <td>0.637363</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.995588</td>\n",
       "      <td>0.713415</td>\n",
       "      <td>0.808756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>0.629032</td>\n",
       "      <td>0</td>\n",
       "      <td>0.793397</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.479055</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.663636</td>\n",
       "      <td>0.689755</td>\n",
       "      <td>0.482071</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.775490</td>\n",
       "      <td>0.491803</td>\n",
       "      <td>0.633431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>357 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     target  partial  tkn_sort  tkn_set   sum_ipa  pshp_soundex_first  \\\n",
       "0         1       57        50       50  0.658986                   0   \n",
       "1         1       38        38       38  0.691532                   0   \n",
       "2         1       89        73       73  0.806452                   0   \n",
       "3         1       83        83       83  0.895161                   1   \n",
       "4         1       74        65       65  0.743176                   0   \n",
       "..      ...      ...       ...      ...       ...                 ...   \n",
       "352       0       83        83       83  0.943548                   0   \n",
       "353       0       75        75       75  0.874552                   1   \n",
       "354       0       80        71       71  0.498208                   0   \n",
       "355       0       67        77       77  0.822581                   1   \n",
       "356       0       86        67       67  0.629032                   0   \n",
       "\n",
       "     iterativesubstring     bisim  discountedlevenshtein  prefix  ...  \\\n",
       "0              0.485480  0.388889               0.383752   0.000  ...   \n",
       "1              0.050000  0.437500               0.366778   0.125  ...   \n",
       "2              0.821263  0.583333               0.495199   0.000  ...   \n",
       "3              0.884677  0.833333               0.818487   0.750  ...   \n",
       "4              0.951613  0.588235               0.472052   0.000  ...   \n",
       "..                  ...       ...                    ...     ...  ...   \n",
       "352            0.897436  0.750000               0.796089   0.000  ...   \n",
       "353            0.804167  0.750000               0.798406   0.625  ...   \n",
       "354            0.800858  0.611111               0.510437   0.000  ...   \n",
       "355            0.852383  0.678571               0.700763   0.500  ...   \n",
       "356            0.793397  0.500000               0.479055   0.000  ...   \n",
       "\n",
       "          mra    editex      saps  flexmetric      jaro  higueramico  \\\n",
       "0    0.666667  0.555556  0.137931    0.566667  0.671958     0.430556   \n",
       "1    0.500000  0.500000  0.304348    0.400000  0.583333     0.375000   \n",
       "2    0.833333  0.500000  0.428571    0.600000  0.822222     0.547619   \n",
       "3    0.500000  0.833333  0.666667    0.833333  0.888889     0.769231   \n",
       "4    0.000000  0.588235  0.319149    0.538235  0.687675     0.490372   \n",
       "..        ...       ...       ...         ...       ...          ...   \n",
       "352  0.833333  0.833333  0.500000    0.833333  0.822222     0.833333   \n",
       "353  0.833333  0.812500  0.565217    0.787500  0.833333     0.750000   \n",
       "354  0.666667  0.666667  0.310345    0.666667  0.741402     0.588889   \n",
       "355  0.833333  0.678571  0.469388    0.700000  0.815873     0.637363   \n",
       "356  0.500000  0.636364  0.166667    0.663636  0.689755     0.482071   \n",
       "\n",
       "        sift4     eudex     aline  phoneticeditdistance  \n",
       "0    0.444444  0.654902  0.602128              0.727599  \n",
       "1    0.375000  0.916667  0.545455              0.897177  \n",
       "2    0.666667  0.786275  0.705882              0.634409  \n",
       "3    0.833333  1.000000  0.873529              0.913978  \n",
       "4    0.588235  0.463725  0.589655              0.646110  \n",
       "..        ...       ...       ...                   ...  \n",
       "352  0.833333  0.866667  0.823529              0.943548  \n",
       "353  0.750000  0.997549  0.937500              0.973790  \n",
       "354  0.666667  0.784804  0.705882              0.655914  \n",
       "355  0.714286  0.995588  0.713415              0.808756  \n",
       "356  0.363636  0.775490  0.491803              0.633431  \n",
       "\n",
       "[357 rows x 23 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_TPOT = df.drop(columns = ['a','b','TM_A','TM_B'])\n",
    "df_TPOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from tpot.builtins import StackingEstimator\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from copy import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'CROWNE PLAZA'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-e9293d293b4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m )\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mexported_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexported_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesting_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'passthrough'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0;31m# trees use different types for X and y, checking them separately.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m         X, y = self._validate_data(X, y, accept_sparse=['csr', 'csc', 'coo'],\n\u001b[0m\u001b[1;32m    410\u001b[0m                                    dtype=DTYPE, multi_output=True)\n\u001b[1;32m    411\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    794\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y cannot be None\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 796\u001b[0;31m     X = check_array(X, accept_sparse=accept_sparse,\n\u001b[0m\u001b[1;32m    797\u001b[0m                     \u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    597\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'CROWNE PLAZA'"
     ]
    }
   ],
   "source": [
    "# NOTE: Make sure that the outcome column is labeled 'target' in the data file\n",
    "tpot_data = df\n",
    "features = tpot_data.drop('target', axis=1)\n",
    "training_features, testing_features, training_target, testing_target = \\\n",
    "            train_test_split(features, tpot_data['target'], random_state=None)\n",
    "\n",
    "# Average CV score on the training set was: 0.8945711361541637\n",
    "exported_pipeline = make_pipeline(\n",
    "    make_union(\n",
    "        FunctionTransformer(copy),\n",
    "        FunctionTransformer(copy)\n",
    "    ),\n",
    "    GradientBoostingClassifier(learning_rate=0.01, max_depth=3, max_features=0.5,\n",
    "                               min_samples_leaf=10, min_samples_split=3,\n",
    "                               n_estimators=100, subsample=0.9500000000000001)\n",
    ")\n",
    "\n",
    "exported_pipeline.fit(training_features, training_target)\n",
    "results = exported_pipeline.predict(testing_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# NOTE: Make sure that the outcome column is labeled 'target' in the data file\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "# Average CV score on the training set was: 0.8945711361541637\n",
    "exported_pipeline = make_pipeline(\n",
    "    GradientBoostingClassifier(learning_rate=0.01, max_depth=3, max_features=0.5, min_samples_leaf=10,\n",
    "                               min_samples_split=3, n_estimators=100, subsample=0.9500000000000001)\n",
    ")\n",
    "\n",
    "exported_pipeline.fit(X_train.drop(['a', 'b', 'TM_A', 'TM_B'],1), y_train)\n",
    "results = exported_pipeline.predict(X_test.drop(['a', 'b', 'TM_A', 'TM_B'], 1))\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from tpot.builtins import StackingEstimator\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from copy import copy\n",
    "\n",
    "# NOTE: Make sure that the outcome column is labeled 'target' in the data file\n",
    "tpot_data = df_TPOT\n",
    "features = tpot_data.drop('target', axis=1)\n",
    "training_features, testing_features, training_target, testing_target = \\\n",
    "            train_test_split(features, tpot_data['target'], random_state=None)\n",
    "\n",
    "# Average CV score on the training set was: 0.8945711361541637\n",
    "exported_pipeline = make_pipeline(\n",
    "    make_union(\n",
    "        FunctionTransformer(copy),\n",
    "        FunctionTransformer(copy)\n",
    "    ),\n",
    "    GradientBoostingClassifier(learning_rate=0.01, max_depth=3, max_features=0.5, min_samples_leaf=10, min_samples_split=3, n_estimators=100, subsample=0.9500000000000001)\n",
    ")\n",
    "\n",
    "exported_pipeline.fit(training_features, training_target)\n",
    "results = exported_pipeline.predict(testing_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_model_1(X_train, y_train, X_test, export = False) :\n",
    "    exported_pipeline = make_pipeline(\n",
    "    GradientBoostingClassifier(\n",
    "        learning_rate=0.01, \n",
    "        max_depth=3, max_features=0.5,\n",
    "        min_samples_leaf=10, min_samples_split=3, \n",
    "        n_estimators=100, subsample=0.9500000000000001)\n",
    "    )\n",
    "\n",
    "    exported_pipeline.fit(X_train, y_train)\n",
    "    results = exported_pipeline.predict(X_test)\n",
    "    \n",
    "    return(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model_1(X_train.drop(['a', 'b', 'TM_A', 'TM_B'],1), y_train, X_test.drop(['a', 'b', 'TM_A', 'TM_B'], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-90-7ed514384f19>:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  oof_pred['predict_proba'] = base_model_1(X_train.drop(['a', 'b', 'TM_A', 'TM_B'], 1),\n",
      "<ipython-input-90-7ed514384f19>:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  oof_pred['target'] = y_test.tolist()\n",
      "<ipython-input-90-7ed514384f19>:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  oof_pred['predict_proba'] = base_model_1(X_train.drop(['a', 'b', 'TM_A', 'TM_B'], 1),\n",
      "<ipython-input-90-7ed514384f19>:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  oof_pred['target'] = y_test.tolist()\n",
      "<ipython-input-90-7ed514384f19>:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  oof_pred['predict_proba'] = base_model_1(X_train.drop(['a', 'b', 'TM_A', 'TM_B'], 1),\n",
      "<ipython-input-90-7ed514384f19>:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  oof_pred['target'] = y_test.tolist()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed fold 1 of 10\n",
      "completed fold 2 of 10\n",
      "completed fold 3 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-90-7ed514384f19>:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  oof_pred['predict_proba'] = base_model_1(X_train.drop(['a', 'b', 'TM_A', 'TM_B'], 1),\n",
      "<ipython-input-90-7ed514384f19>:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  oof_pred['target'] = y_test.tolist()\n",
      "<ipython-input-90-7ed514384f19>:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  oof_pred['predict_proba'] = base_model_1(X_train.drop(['a', 'b', 'TM_A', 'TM_B'], 1),\n",
      "<ipython-input-90-7ed514384f19>:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  oof_pred['target'] = y_test.tolist()\n",
      "<ipython-input-90-7ed514384f19>:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  oof_pred['predict_proba'] = base_model_1(X_train.drop(['a', 'b', 'TM_A', 'TM_B'], 1),\n",
      "<ipython-input-90-7ed514384f19>:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  oof_pred['target'] = y_test.tolist()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed fold 4 of 10\n",
      "completed fold 5 of 10\n",
      "completed fold 6 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-90-7ed514384f19>:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  oof_pred['predict_proba'] = base_model_1(X_train.drop(['a', 'b', 'TM_A', 'TM_B'], 1),\n",
      "<ipython-input-90-7ed514384f19>:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  oof_pred['target'] = y_test.tolist()\n",
      "<ipython-input-90-7ed514384f19>:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  oof_pred['predict_proba'] = base_model_1(X_train.drop(['a', 'b', 'TM_A', 'TM_B'], 1),\n",
      "<ipython-input-90-7ed514384f19>:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  oof_pred['target'] = y_test.tolist()\n",
      "<ipython-input-90-7ed514384f19>:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  oof_pred['predict_proba'] = base_model_1(X_train.drop(['a', 'b', 'TM_A', 'TM_B'], 1),\n",
      "<ipython-input-90-7ed514384f19>:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  oof_pred['target'] = y_test.tolist()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed fold 7 of 10\n",
      "completed fold 8 of 10\n",
      "completed fold 9 of 10\n",
      "completed fold 10 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-90-7ed514384f19>:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  oof_pred['predict_proba'] = base_model_1(X_train.drop(['a', 'b', 'TM_A', 'TM_B'], 1),\n",
      "<ipython-input-90-7ed514384f19>:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  oof_pred['target'] = y_test.tolist()\n"
     ]
    }
   ],
   "source": [
    "# Stratified K-Folds cross-validator\n",
    "meta_training = pd.DataFrame()\n",
    "\n",
    "stratified_kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "fold = 1\n",
    "for train_index, test_index in stratified_kfold.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    oof_pred = X_test[['TM_A', 'TM_B']]\n",
    "    \n",
    "    oof_pred['predict_proba'] = base_model_1(X_train.drop(['a', 'b', 'TM_A', 'TM_B'], 1),\n",
    "                                      y_train,\n",
    "                                      X_test.drop(['a', 'b', 'TM_A', 'TM_B'], 1))\n",
    "\n",
    "#     oof_pred['siamese_sim'] = base_model_2(X_train[['name_a', 'name_b']],\n",
    "#                                       y_train,\n",
    "#                                       X_test[['name_a', 'name_b']])\n",
    "    \n",
    "    oof_pred['target'] = y_test.tolist()\n",
    "    \n",
    "    print('completed fold {} of 10'.format(fold))\n",
    "    fold += 1\n",
    "\n",
    "    meta_training = meta_training.append(oof_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TM_A</th>\n",
       "      <th>TM_B</th>\n",
       "      <th>predict_proba</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>cme</td>\n",
       "      <td>irsiacmi</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>horizon</td>\n",
       "      <td>horizonrisksolutions</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>realpetfoodcompany</td>\n",
       "      <td>therealpetfoodcompany</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>rives</td>\n",
       "      <td>rivers</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>fidelity</td>\n",
       "      <td>fideres</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>helloenergy</td>\n",
       "      <td>hellodiet</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>merano</td>\n",
       "      <td>murano</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>lifestyle</td>\n",
       "      <td>lifestylefloors</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>redinside</td>\n",
       "      <td>inside</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>pip</td>\n",
       "      <td>pipsisland</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   TM_A                   TM_B  predict_proba  target\n",
       "302                 cme               irsiacmi              1       0\n",
       "246             horizon   horizonrisksolutions              1       1\n",
       "75   realpetfoodcompany  therealpetfoodcompany              1       1\n",
       "300               rives                 rivers              1       0\n",
       "295            fidelity                fideres              1       0\n",
       "151         helloenergy              hellodiet              1       1\n",
       "347              merano                 murano              1       0\n",
       "219           lifestyle        lifestylefloors              1       1\n",
       "88            redinside                 inside              1       1\n",
       "329                 pip             pipsisland              1       0"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_training.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta-Model: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 357/357 [00:00<00:00, 18798.38it/s]\n",
      "100%|██████████| 357/357 [00:00<00:00, 4536.57it/s]\n",
      "100%|██████████| 357/357 [00:00<00:00, 3375.72it/s]\n",
      "100%|██████████| 357/357 [00:00<00:00, 25761.14it/s]\n",
      "100%|██████████| 357/357 [00:00<00:00, 11281.81it/s]\n",
      "100%|██████████| 357/357 [00:00<00:00, 24801.92it/s]\n",
      "100%|██████████| 357/357 [00:00<00:00, 12019.03it/s]\n",
      "100%|██████████| 357/357 [00:00<00:00, 10221.56it/s]\n",
      "100%|██████████| 357/357 [00:00<00:00, 2003.51it/s]\n",
      "100%|██████████| 357/357 [00:00<00:00, 3166.01it/s]\n",
      "100%|██████████| 357/357 [00:00<00:00, 2286.18it/s]\n",
      "100%|██████████| 357/357 [00:00<00:00, 11813.82it/s]\n",
      "100%|██████████| 357/357 [00:01<00:00, 246.88it/s]\n",
      "100%|██████████| 357/357 [00:00<00:00, 16471.41it/s]\n",
      "100%|██████████| 357/357 [00:00<00:00, 9039.83it/s]\n",
      "100%|██████████| 357/357 [00:01<00:00, 196.14it/s]\n",
      "100%|██████████| 357/357 [00:00<00:00, 1103.16it/s]\n"
     ]
    }
   ],
   "source": [
    "df= featurize(meta_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>predict_proba</th>\n",
       "      <th>target</th>\n",
       "      <th>TM_A</th>\n",
       "      <th>TM_B</th>\n",
       "      <th>partial</th>\n",
       "      <th>tkn_sort</th>\n",
       "      <th>tkn_set</th>\n",
       "      <th>sum_ipa</th>\n",
       "      <th>...</th>\n",
       "      <th>mra</th>\n",
       "      <th>editex</th>\n",
       "      <th>saps</th>\n",
       "      <th>flexmetric</th>\n",
       "      <th>jaro</th>\n",
       "      <th>higueramico</th>\n",
       "      <th>sift4</th>\n",
       "      <th>eudex</th>\n",
       "      <th>aline</th>\n",
       "      <th>phoneticeditdistance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zirco</td>\n",
       "      <td>cozirc</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>zirco</td>\n",
       "      <td>cozirc</td>\n",
       "      <td>89</td>\n",
       "      <td>73</td>\n",
       "      <td>73</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>0.547619</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.786275</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.634409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>frickinchicken</td>\n",
       "      <td>flipnchicken</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>frickinchicken</td>\n",
       "      <td>flipnchicken</td>\n",
       "      <td>75</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.757143</td>\n",
       "      <td>0.782540</td>\n",
       "      <td>0.708791</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.919118</td>\n",
       "      <td>0.758537</td>\n",
       "      <td>0.835253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>kresco</td>\n",
       "      <td>cresco</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>kresco</td>\n",
       "      <td>cresco</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.874510</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.994624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>starbucks</td>\n",
       "      <td>sambucks</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>starbucks</td>\n",
       "      <td>sambucks</td>\n",
       "      <td>75</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>0.891129</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.844444</td>\n",
       "      <td>0.884259</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.798039</td>\n",
       "      <td>0.709091</td>\n",
       "      <td>0.867384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>zlide</td>\n",
       "      <td>logicslide</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>zlide</td>\n",
       "      <td>logicslide</td>\n",
       "      <td>80</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>0.673387</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.254365</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.762255</td>\n",
       "      <td>0.462963</td>\n",
       "      <td>0.496774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 a             b  predict_proba  target            TM_A  \\\n",
       "2            zirco        cozirc              1       1           zirco   \n",
       "8   frickinchicken  flipnchicken              1       1  frickinchicken   \n",
       "12          kresco        cresco              1       1          kresco   \n",
       "14       starbucks      sambucks              1       1       starbucks   \n",
       "45           zlide    logicslide              1       1           zlide   \n",
       "\n",
       "            TM_B  partial  tkn_sort  tkn_set   sum_ipa  ...       mra  \\\n",
       "2         cozirc       89        73       73  0.806452  ...  0.833333   \n",
       "8   flipnchicken       75        77       77  0.666667  ...  0.666667   \n",
       "12        cresco       83        83       83  1.000000  ...  0.833333   \n",
       "14      sambucks       75        82       82  0.891129  ...  0.666667   \n",
       "45    logicslide       80        53       53  0.673387  ...  0.000000   \n",
       "\n",
       "      editex      saps  flexmetric      jaro  higueramico     sift4     eudex  \\\n",
       "2   0.500000  0.428571    0.600000  0.822222     0.547619  0.666667  0.786275   \n",
       "8   0.785714  0.500000    0.757143  0.782540     0.708791  0.642857  0.919118   \n",
       "12  0.916667  0.619048    0.983333  0.888889     0.833333  0.833333  0.874510   \n",
       "14  0.777778  0.676471    0.844444  0.884259     0.777778  0.777778  0.798039   \n",
       "45  0.450000  0.085714    0.550000  0.533333     0.254365  0.200000  0.762255   \n",
       "\n",
       "       aline  phoneticeditdistance  \n",
       "2   0.705882              0.634409  \n",
       "8   0.758537              0.835253  \n",
       "12  0.911765              0.994624  \n",
       "14  0.709091              0.867384  \n",
       "45  0.462963              0.496774  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [col for col in df.columns if col not in ['a', 'b', 'TM_A', 'TM_B', 'target', 'predict_proba']]\n",
    "comb2 = list(combinations(cols, 2))\n",
    "comb3 = list(combinations(cols, 3))\n",
    "colgrid = [(col,)for col in cols]+comb2+comb3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df, df.target, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression()\n",
    "grid_clf = GridSearchCV(clf, param_grid = {'C':np.logspace(-4, 4, 20)}, scoring = 'precision', verbose=0)\n",
    "\n",
    "scores = []\n",
    "for cols in colgrid:\n",
    "    grid_clf.fit(X_train[['predict_proba']+list(cols)], y_train)\n",
    "    y_pred = grid_clf.predict(X_val[['predict_proba']+list(cols)])\n",
    "    tn, fp, fn, tp = confusion_matrix(y_val, y_pred).ravel()\n",
    "    scores.append([str(cols), tn, fp, fn, tp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df.columns = ['features', 'tn', 'fp', 'fn', 'tp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>('partial',)</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>('tkn_sort',)</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>('tkn_set',)</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>('sum_ipa',)</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>('pshp_soundex_first',)</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  features  tn  fp  fn  tp\n",
       "0             ('partial',)   0  13   0  59\n",
       "1            ('tkn_sort',)   0  13   0  59\n",
       "2             ('tkn_set',)   0  13   0  59\n",
       "3             ('sum_ipa',)   0  13   0  59\n",
       "4  ('pshp_soundex_first',)   0  13   0  59"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df['error'] = scores_df['fp'] + scores_df['fn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = scores_df.sort_values(['error', 'fp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df, df.target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cols = ['predict_proba', 'tkn_set', 'iterativesubstring', 'strcmp95']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression()\n",
    "grid_clf = GridSearchCV(clf, param_grid = {'C':np.logspace(-4, 4, 20)}, scoring='precision')\n",
    "grid_clf.fit(X_train[selected_cols], y_train)\n",
    "y_pred = grid_clf.predict(X_test[selected_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 545.5594781168514}\n"
     ]
    }
   ],
   "source": [
    "print(grid_clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_test, y_pred):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    conf_matrix = pd.DataFrame(data=cm, columns=['Predicted: 0', 'Predicted: 1'], index=['Actual: 0', 'Actual: 1'])\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        10\n",
      "           1       0.86      1.00      0.93        62\n",
      "\n",
      "    accuracy                           0.86        72\n",
      "   macro avg       0.43      0.50      0.46        72\n",
      "weighted avg       0.74      0.86      0.80        72\n",
      "\n",
      "           Predicted: 0  Predicted: 1\n",
      "Actual: 0             0            10\n",
      "Actual: 1             0            62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seannguyen/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc curve and auc\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.6, 0.3, 'AUC=0.594')"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(7,7))\n",
    "baseline_probs = [0 for _ in range(len(y_test))]\n",
    "\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = grid_clf.predict_proba(X_test[selected_cols])\n",
    "probs = probs[:, 1]\n",
    "\n",
    "# calculate scores\n",
    "baseline_auc = roc_auc_score(y_test, baseline_probs)\n",
    "auc = roc_auc_score(y_test, probs)\n",
    "auc = ('AUC=%.3f' % (auc))\n",
    "\n",
    "# calculate roc curves\n",
    "baseline_fpr, baseline_tpr, _ = roc_curve(y_test, baseline_probs)\n",
    "fpr, tpr, _ = roc_curve(y_test, probs)\n",
    "\n",
    "# plot the roc curve for the model\n",
    "ax.plot(baseline_fpr, baseline_tpr, color='gray')\n",
    "ax.plot(fpr, tpr, marker='.', color='black')\n",
    "\n",
    "# axis labels\n",
    "ax.set_xlabel('False Positive Rate',fontsize=12)\n",
    "ax.set_ylabel('True Positive Rate',fontsize=12)\n",
    "ax.set_title('Receiver Operating Characteristic', fontsize=16)\n",
    "plt.text(.6, .3, auc, fontsize=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TPOT AutoML Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpot import TPOTRegressor\n",
    "\n",
    "pipeline_optimizer = TPOTRegressor(\n",
    "        scoring = 'f1', \n",
    "        generations=100,\n",
    "        verbosity=2,\n",
    "        n_jobs=-1   # Utilizes all available CPU cores\n",
    "        ) \n",
    "pipeline_optimizer.fit(X_train.drop(['a', 'b', 'TM_A', 'TM_B'],1), y_train)\n",
    "\n",
    "exported_pipeline = make_pipeline("
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
