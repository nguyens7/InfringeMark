{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TM_A</th>\n",
       "      <th>TM_B</th>\n",
       "      <th>Decision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Simoniz</td>\n",
       "      <td>Permanize</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Magnavoc</td>\n",
       "      <td>Multivox</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Zirco</td>\n",
       "      <td>Cozirc</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Platinum Puff</td>\n",
       "      <td>Platinum Plus</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Maternity Yours</td>\n",
       "      <td>Your Maternity Shop</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>Lilton</td>\n",
       "      <td>Wilton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>Nutricia</td>\n",
       "      <td>Nutritea</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>Glenreidh</td>\n",
       "      <td>An Reidhe</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>No Gunk No Junk</td>\n",
       "      <td>No Gunk Just Funk</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>e-Relief</td>\n",
       "      <td>LIGHT RELIEF</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>357 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                TM_A                 TM_B  Decision\n",
       "0            Simoniz            Permanize         1\n",
       "1           Magnavoc             Multivox         1\n",
       "2              Zirco               Cozirc         1\n",
       "3      Platinum Puff        Platinum Plus         1\n",
       "4    Maternity Yours  Your Maternity Shop         1\n",
       "..               ...                  ...       ...\n",
       "352           Lilton               Wilton         0\n",
       "353         Nutricia             Nutritea         0\n",
       "354        Glenreidh            An Reidhe         0\n",
       "355  No Gunk No Junk    No Gunk Just Funk         0\n",
       "356         e-Relief         LIGHT RELIEF         0\n",
       "\n",
       "[357 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cases = pd.read_csv('Data.nosync/Similar_TM.csv')\n",
    "cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unidecode\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "from abydos.distance import (IterativeSubString, BISIM, DiscountedLevenshtein, Prefix, LCSstr, MLIPNS, Strcmp95,\n",
    "MRA, Editex, SAPS, FlexMetric, JaroWinkler, HigueraMico, Sift4, Eudex, ALINE, PhoneticEditDistance)\n",
    "\n",
    "from abydos.phonetic import PSHPSoundexFirst, Ainsworth\n",
    "pshp_soundex_first = PSHPSoundexFirst()\n",
    "pe = Ainsworth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "iss = IterativeSubString()\n",
    "bisim = BISIM()\n",
    "dlev = DiscountedLevenshtein()\n",
    "prefix = Prefix()\n",
    "lcs = LCSstr()\n",
    "mlipns = MLIPNS()\n",
    "strcmp95 = Strcmp95()\n",
    "mra = MRA()\n",
    "editex = Editex()\n",
    "saps = SAPS()\n",
    "flexmetric = FlexMetric()\n",
    "jaro = JaroWinkler(mode='Jaro')\n",
    "higuera_mico = HigueraMico()\n",
    "sift4 = Sift4()\n",
    "eudex = Eudex()\n",
    "aline = ALINE()\n",
    "phonetic_edit = PhoneticEditDistance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "algos = [iss, bisim, dlev, prefix, lcs, mlipns, strcmp95, mra, editex, saps, flexmetric, jaro, higuera_mico, sift4, eudex,\n",
    "         aline, phonetic_edit]\n",
    "\n",
    "algo_names = ['iterativesubstring', 'bisim', 'discountedlevenshtein', 'prefix', 'lcsstr', 'mlipns', 'strcmp95', 'mra',\n",
    "              'editex', 'saps', 'flexmetric', 'jaro', 'higueramico', 'sift4', 'eudex', 'aline',\n",
    "              'phoneticeditdistance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abydos.phones import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_ipa(name_a, name_b):\n",
    "    feat1 = ipa_to_features(pe.encode(name_a))\n",
    "    feat2 = ipa_to_features(pe.encode(name_b))\n",
    "    score = sum(cmp_features(f1, f2) for f1, f2 in zip(feat1, feat2))/len(feat1)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def featurize(df):\n",
    "    if len(df.columns)==3:\n",
    "        df.columns=['a', 'b', 'Decision']\n",
    "    elif len(df.columns)==2:\n",
    "        df.columns=['a', 'b']\n",
    "    else:\n",
    "        df = df.rename(columns={df.columns[0]: 'a', df.columns[1]: 'b' })\n",
    "        \n",
    "    df['TM_A'] = df.apply(lambda row: re.sub(\n",
    "        '[^a-zA-Z]+', '', unidecode.unidecode(row['a']).lower()), axis=1)\n",
    "    df['TM_B'] = df.apply(lambda row: re.sub(\n",
    "        '[^a-zA-Z]+', '', unidecode.unidecode(row['b']).lower()), axis=1)\n",
    "    \n",
    "\n",
    "    df['partial'] = df.apply(lambda row: fuzz.partial_ratio(row.TM_A,row.TM_B), axis=1)\n",
    "    df['tkn_sort'] = df.apply(lambda row: fuzz.token_sort_ratio(row.TM_A,row.TM_B), axis=1)\n",
    "    df['tkn_set'] = df.apply(lambda row: fuzz.token_set_ratio(row.TM_A,row.TM_B), axis=1)\n",
    "    \n",
    "    df['sum_ipa'] = df.apply(lambda row: sum_ipa(row.TM_A,row.TM_B), axis=1)\n",
    "    \n",
    "    df['pshp_soundex_first'] = df.apply(\n",
    "        lambda row: 1 if pshp_soundex_first.encode(row.TM_A)==pshp_soundex_first.encode(row.TM_B) else 0, axis=1)\n",
    "    \n",
    "    for i, algo in enumerate(algos):\n",
    "            df[algo_names[i]] = df.progress_apply(lambda row: algo.sim(row.TM_A, row.TM_B), axis=1)\n",
    "            \n",
    "#     df.drop(['syll_a', 'syll_b'], axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from itertools import combinations\n",
    "import random\n",
    "random.seed(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>target</th>\n",
       "      <th>TM_A</th>\n",
       "      <th>TM_B</th>\n",
       "      <th>partial</th>\n",
       "      <th>tkn_sort</th>\n",
       "      <th>tkn_set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Zirco</td>\n",
       "      <td>Cozirc</td>\n",
       "      <td>1</td>\n",
       "      <td>zirco</td>\n",
       "      <td>cozirc</td>\n",
       "      <td>89</td>\n",
       "      <td>73</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       a       b  target   TM_A    TM_B  partial  tkn_sort  tkn_set\n",
       "2  Zirco  Cozirc       1  zirco  cozirc       89        73       73"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftest=cases.loc[[2]]\n",
    "dftest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seannguyen/opt/anaconda3/lib/python3.8/site-packages/tqdm/std.py:668: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 357/357 [00:00<00:00, 21014.49it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 357/357 [00:00<00:00, 4801.47it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 357/357 [00:00<00:00, 3606.40it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 357/357 [00:00<00:00, 22799.64it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 357/357 [00:00<00:00, 12878.36it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 357/357 [00:00<00:00, 23508.38it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 357/357 [00:00<00:00, 12416.49it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 357/357 [00:00<00:00, 12801.18it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 357/357 [00:00<00:00, 2137.41it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 357/357 [00:00<00:00, 3416.98it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 357/357 [00:00<00:00, 2425.57it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 357/357 [00:00<00:00, 13135.72it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 357/357 [00:01<00:00, 258.27it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 357/357 [00:00<00:00, 19430.67it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 357/357 [00:00<00:00, 11108.31it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 357/357 [00:01<00:00, 202.77it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 357/357 [00:00<00:00, 1125.50it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>target</th>\n",
       "      <th>TM_A</th>\n",
       "      <th>TM_B</th>\n",
       "      <th>partial</th>\n",
       "      <th>tkn_sort</th>\n",
       "      <th>tkn_set</th>\n",
       "      <th>sum_ipa</th>\n",
       "      <th>pshp_soundex_first</th>\n",
       "      <th>...</th>\n",
       "      <th>mra</th>\n",
       "      <th>editex</th>\n",
       "      <th>saps</th>\n",
       "      <th>flexmetric</th>\n",
       "      <th>jaro</th>\n",
       "      <th>higueramico</th>\n",
       "      <th>sift4</th>\n",
       "      <th>eudex</th>\n",
       "      <th>aline</th>\n",
       "      <th>phoneticeditdistance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Simoniz</td>\n",
       "      <td>Permanize</td>\n",
       "      <td>1</td>\n",
       "      <td>simoniz</td>\n",
       "      <td>permanize</td>\n",
       "      <td>57</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>0.658986</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.671958</td>\n",
       "      <td>0.430556</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.654902</td>\n",
       "      <td>0.602128</td>\n",
       "      <td>0.727599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Magnavoc</td>\n",
       "      <td>Multivox</td>\n",
       "      <td>1</td>\n",
       "      <td>magnavoc</td>\n",
       "      <td>multivox</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>0.691532</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.897177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Zirco</td>\n",
       "      <td>Cozirc</td>\n",
       "      <td>1</td>\n",
       "      <td>zirco</td>\n",
       "      <td>cozirc</td>\n",
       "      <td>89</td>\n",
       "      <td>73</td>\n",
       "      <td>73</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>0.547619</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.786275</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.634409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Platinum Puff</td>\n",
       "      <td>Platinum Plus</td>\n",
       "      <td>1</td>\n",
       "      <td>platinumpuff</td>\n",
       "      <td>platinumplus</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>0.895161</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.873529</td>\n",
       "      <td>0.913978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Maternity Yours</td>\n",
       "      <td>Your Maternity Shop</td>\n",
       "      <td>1</td>\n",
       "      <td>maternityyours</td>\n",
       "      <td>yourmaternityshop</td>\n",
       "      <td>74</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>0.743176</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.319149</td>\n",
       "      <td>0.538235</td>\n",
       "      <td>0.687675</td>\n",
       "      <td>0.490372</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.463725</td>\n",
       "      <td>0.589655</td>\n",
       "      <td>0.646110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>Lilton</td>\n",
       "      <td>Wilton</td>\n",
       "      <td>0</td>\n",
       "      <td>lilton</td>\n",
       "      <td>wilton</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>0.943548</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.943548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>Nutricia</td>\n",
       "      <td>Nutritea</td>\n",
       "      <td>0</td>\n",
       "      <td>nutricia</td>\n",
       "      <td>nutritea</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>0.874552</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.787500</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.997549</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.973790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>Glenreidh</td>\n",
       "      <td>An Reidhe</td>\n",
       "      <td>0</td>\n",
       "      <td>glenreidh</td>\n",
       "      <td>anreidhe</td>\n",
       "      <td>80</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>0.498208</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.741402</td>\n",
       "      <td>0.588889</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.784804</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.655914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>No Gunk No Junk</td>\n",
       "      <td>No Gunk Just Funk</td>\n",
       "      <td>0</td>\n",
       "      <td>nogunknojunk</td>\n",
       "      <td>nogunkjustfunk</td>\n",
       "      <td>67</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.469388</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.815873</td>\n",
       "      <td>0.637363</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.995588</td>\n",
       "      <td>0.713415</td>\n",
       "      <td>0.808756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>e-Relief</td>\n",
       "      <td>LIGHT RELIEF</td>\n",
       "      <td>0</td>\n",
       "      <td>erelief</td>\n",
       "      <td>lightrelief</td>\n",
       "      <td>86</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>0.629032</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.663636</td>\n",
       "      <td>0.689755</td>\n",
       "      <td>0.482071</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.775490</td>\n",
       "      <td>0.491803</td>\n",
       "      <td>0.633431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>357 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   a                    b  target            TM_A  \\\n",
       "0            Simoniz            Permanize       1         simoniz   \n",
       "1           Magnavoc             Multivox       1        magnavoc   \n",
       "2              Zirco               Cozirc       1           zirco   \n",
       "3      Platinum Puff        Platinum Plus       1    platinumpuff   \n",
       "4    Maternity Yours  Your Maternity Shop       1  maternityyours   \n",
       "..               ...                  ...     ...             ...   \n",
       "352           Lilton               Wilton       0          lilton   \n",
       "353         Nutricia             Nutritea       0        nutricia   \n",
       "354        Glenreidh            An Reidhe       0       glenreidh   \n",
       "355  No Gunk No Junk    No Gunk Just Funk       0    nogunknojunk   \n",
       "356         e-Relief         LIGHT RELIEF       0         erelief   \n",
       "\n",
       "                  TM_B  partial  tkn_sort  tkn_set   sum_ipa  \\\n",
       "0            permanize       57        50       50  0.658986   \n",
       "1             multivox       38        38       38  0.691532   \n",
       "2               cozirc       89        73       73  0.806452   \n",
       "3         platinumplus       83        83       83  0.895161   \n",
       "4    yourmaternityshop       74        65       65  0.743176   \n",
       "..                 ...      ...       ...      ...       ...   \n",
       "352             wilton       83        83       83  0.943548   \n",
       "353           nutritea       75        75       75  0.874552   \n",
       "354           anreidhe       80        71       71  0.498208   \n",
       "355     nogunkjustfunk       67        77       77  0.822581   \n",
       "356        lightrelief       86        67       67  0.629032   \n",
       "\n",
       "     pshp_soundex_first  ...       mra    editex      saps  flexmetric  \\\n",
       "0                     0  ...  0.666667  0.555556  0.137931    0.566667   \n",
       "1                     0  ...  0.500000  0.500000  0.304348    0.400000   \n",
       "2                     0  ...  0.833333  0.500000  0.428571    0.600000   \n",
       "3                     1  ...  0.500000  0.833333  0.666667    0.833333   \n",
       "4                     0  ...  0.000000  0.588235  0.319149    0.538235   \n",
       "..                  ...  ...       ...       ...       ...         ...   \n",
       "352                   0  ...  0.833333  0.833333  0.500000    0.833333   \n",
       "353                   1  ...  0.833333  0.812500  0.565217    0.787500   \n",
       "354                   0  ...  0.666667  0.666667  0.310345    0.666667   \n",
       "355                   1  ...  0.833333  0.678571  0.469388    0.700000   \n",
       "356                   0  ...  0.500000  0.636364  0.166667    0.663636   \n",
       "\n",
       "         jaro  higueramico     sift4     eudex     aline  phoneticeditdistance  \n",
       "0    0.671958     0.430556  0.444444  0.654902  0.602128              0.727599  \n",
       "1    0.583333     0.375000  0.375000  0.916667  0.545455              0.897177  \n",
       "2    0.822222     0.547619  0.666667  0.786275  0.705882              0.634409  \n",
       "3    0.888889     0.769231  0.833333  1.000000  0.873529              0.913978  \n",
       "4    0.687675     0.490372  0.588235  0.463725  0.589655              0.646110  \n",
       "..        ...          ...       ...       ...       ...                   ...  \n",
       "352  0.822222     0.833333  0.833333  0.866667  0.823529              0.943548  \n",
       "353  0.833333     0.750000  0.750000  0.997549  0.937500              0.973790  \n",
       "354  0.741402     0.588889  0.666667  0.784804  0.705882              0.655914  \n",
       "355  0.815873     0.637363  0.714286  0.995588  0.713415              0.808756  \n",
       "356  0.689755     0.482071  0.363636  0.775490  0.491803              0.633431  \n",
       "\n",
       "[357 rows x 27 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "df = featurize(cases)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export clean data to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Data.nosync/TM_features.csv', index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.target\n",
    "X = df.drop('target',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpot import TPOTClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Optimization Progress', max=10100.0, style=ProgressStyle(â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.8910336950314107\n",
      "Generation 2 - Current best internal CV score: 0.8910336950314107\n",
      "Generation 3 - Current best internal CV score: 0.8927850751951265\n",
      "Generation 4 - Current best internal CV score: 0.8927850751951265\n",
      "Generation 5 - Current best internal CV score: 0.8927850751951265\n",
      "Generation 6 - Current best internal CV score: 0.8927850751951265\n",
      "Generation 7 - Current best internal CV score: 0.8927850751951265\n",
      "Generation 8 - Current best internal CV score: 0.8927850751951265\n",
      "Generation 9 - Current best internal CV score: 0.8927850751951265\n",
      "Generation 10 - Current best internal CV score: 0.8927850751951265\n",
      "Generation 11 - Current best internal CV score: 0.8927850751951265\n",
      "Generation 12 - Current best internal CV score: 0.8927850751951265\n",
      "Generation 13 - Current best internal CV score: 0.8927850751951265\n",
      "Generation 14 - Current best internal CV score: 0.8927850751951265\n",
      "Generation 15 - Current best internal CV score: 0.8927850751951265\n",
      "Generation 16 - Current best internal CV score: 0.8927850751951265\n",
      "Generation 17 - Current best internal CV score: 0.8927850751951265\n",
      "Generation 18 - Current best internal CV score: 0.8941442984960976\n",
      "Generation 19 - Current best internal CV score: 0.8941442984960976\n",
      "Generation 20 - Current best internal CV score: 0.8941442984960976\n",
      "Generation 21 - Current best internal CV score: 0.8945364553588426\n",
      "Generation 22 - Current best internal CV score: 0.8945364553588426\n",
      "Generation 23 - Current best internal CV score: 0.8945364553588426\n",
      "Generation 24 - Current best internal CV score: 0.8945364553588426\n",
      "Generation 25 - Current best internal CV score: 0.8945364553588426\n",
      "Generation 26 - Current best internal CV score: 0.8945364553588426\n",
      "Generation 27 - Current best internal CV score: 0.8945364553588426\n",
      "Generation 28 - Current best internal CV score: 0.8945364553588426\n",
      "Generation 29 - Current best internal CV score: 0.8945364553588426\n",
      "Generation 30 - Current best internal CV score: 0.8945364553588426\n",
      "Generation 31 - Current best internal CV score: 0.8945364553588426\n",
      "Generation 32 - Current best internal CV score: 0.8945364553588426\n",
      "Generation 33 - Current best internal CV score: 0.8945364553588426\n",
      "Generation 34 - Current best internal CV score: 0.8945364553588426\n",
      "Generation 35 - Current best internal CV score: 0.8945364553588426\n",
      "Generation 36 - Current best internal CV score: 0.8945364553588426\n",
      "Generation 37 - Current best internal CV score: 0.8945364553588426\n",
      "Generation 38 - Current best internal CV score: 0.8945364553588426\n",
      "Generation 39 - Current best internal CV score: 0.8945364553588426\n",
      "Generation 40 - Current best internal CV score: 0.8945364553588426\n",
      "Generation 41 - Current best internal CV score: 0.8945364553588426\n",
      "Generation 42 - Current best internal CV score: 0.8945364553588426\n",
      "Generation 43 - Current best internal CV score: 0.8945711361541637\n",
      "Generation 44 - Current best internal CV score: 0.8945711361541637\n",
      "Generation 45 - Current best internal CV score: 0.8945711361541637\n",
      "Generation 46 - Current best internal CV score: 0.8945711361541637\n",
      "Generation 47 - Current best internal CV score: 0.8945711361541637\n",
      "Generation 48 - Current best internal CV score: 0.8945711361541637\n",
      "Generation 49 - Current best internal CV score: 0.8945711361541637\n",
      "Generation 50 - Current best internal CV score: 0.8945711361541637\n",
      "Generation 51 - Current best internal CV score: 0.8945711361541637\n",
      "Generation 52 - Current best internal CV score: 0.8945711361541637\n",
      "Generation 53 - Current best internal CV score: 0.8945711361541637\n",
      "Generation 54 - Current best internal CV score: 0.8945711361541637\n",
      "Generation 55 - Current best internal CV score: 0.8945711361541637\n",
      "Generation 56 - Current best internal CV score: 0.8945711361541637\n",
      "Generation 57 - Current best internal CV score: 0.8945711361541637\n",
      "Generation 58 - Current best internal CV score: 0.8945711361541637\n",
      "Generation 59 - Current best internal CV score: 0.8945711361541637\n",
      "Generation 60 - Current best internal CV score: 0.8945711361541637\n",
      "Generation 61 - Current best internal CV score: 0.8945711361541637\n",
      "Generation 62 - Current best internal CV score: 0.8945711361541637\n",
      "Generation 63 - Current best internal CV score: 0.8945711361541637\n",
      "Generation 64 - Current best internal CV score: 0.8945711361541637\n",
      "Generation 65 - Current best internal CV score: 0.8945711361541637\n",
      "Generation 66 - Current best internal CV score: 0.8945711361541637\n",
      "Generation 67 - Current best internal CV score: 0.8945711361541637\n",
      "Generation 68 - Current best internal CV score: 0.8945711361541637\n",
      "Generation 69 - Current best internal CV score: 0.8945711361541637\n",
      "Generation 70 - Current best internal CV score: 0.8945711361541637\n",
      "Generation 71 - Current best internal CV score: 0.8945711361541637\n",
      "Generation 72 - Current best internal CV score: 0.8945711361541637\n",
      "Generation 73 - Current best internal CV score: 0.8945711361541637\n",
      "Generation 74 - Current best internal CV score: 0.8945711361541637\n",
      "Generation 75 - Current best internal CV score: 0.8945711361541637\n",
      "Generation 76 - Current best internal CV score: 0.8945711361541637\n",
      "Generation 77 - Current best internal CV score: 0.8945711361541637\n",
      "Generation 78 - Current best internal CV score: 0.8945711361541637\n",
      "Generation 79 - Current best internal CV score: 0.8945711361541637\n",
      "Generation 80 - Current best internal CV score: 0.8945711361541637\n",
      "Generation 81 - Current best internal CV score: 0.8945711361541637\n",
      "Generation 82 - Current best internal CV score: 0.8945711361541637\n",
      "Generation 83 - Current best internal CV score: 0.8945711361541637\n",
      "Generation 84 - Current best internal CV score: 0.8945711361541637\n",
      "Generation 85 - Current best internal CV score: 0.8945711361541637\n",
      "Generation 86 - Current best internal CV score: 0.8945711361541637\n",
      "Generation 87 - Current best internal CV score: 0.8945711361541637\n",
      "Generation 88 - Current best internal CV score: 0.8945711361541637\n",
      "Generation 89 - Current best internal CV score: 0.8945711361541637\n",
      "Generation 90 - Current best internal CV score: 0.8945711361541637\n",
      "Generation 91 - Current best internal CV score: 0.8945711361541637\n",
      "Generation 92 - Current best internal CV score: 0.8945711361541637\n",
      "Generation 93 - Current best internal CV score: 0.8945711361541637\n",
      "Generation 94 - Current best internal CV score: 0.8945711361541637\n",
      "Generation 95 - Current best internal CV score: 0.8945711361541637\n",
      "Generation 96 - Current best internal CV score: 0.8945711361541637\n",
      "Generation 97 - Current best internal CV score: 0.8945711361541637\n",
      "Generation 98 - Current best internal CV score: 0.8945711361541637\n",
      "Generation 99 - Current best internal CV score: 0.8945711361541637\n",
      "Generation 100 - Current best internal CV score: 0.8945711361541637\n",
      "Best pipeline: GradientBoostingClassifier(CombineDFs(input_matrix, input_matrix), learning_rate=0.01, max_depth=3, max_features=0.5, min_samples_leaf=10, min_samples_split=3, n_estimators=100, subsample=0.9500000000000001)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TPOTClassifier(log_file=<ipykernel.iostream.OutStream object at 0x7f9666656a90>,\n",
       "               n_jobs=-1, scoring='f1', verbosity=2)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_optimizer = TPOTClassifier(\n",
    "        scoring = 'f1', \n",
    "        generations=100,\n",
    "        verbosity=2,\n",
    "        n_jobs=-1   # Utilizes all available CPU cores\n",
    "        ) \n",
    "pipeline_optimizer.fit(X_train.drop(['a', 'b', 'TM_A', 'TM_B'],1), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8837209302325582\n"
     ]
    }
   ],
   "source": [
    "print(pipeline_optimizer.score(X_test.drop(['a', 'b', 'TM_A', 'TM_B'], 1), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_optimizer.export('tpot_exported_calssifier_pipeline.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'CANDEY'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-b3d105273bf6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m )\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mexported_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexported_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesting_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'passthrough'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0;31m# trees use different types for X and y, checking them separately.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m         X, y = self._validate_data(X, y, accept_sparse=['csr', 'csc', 'coo'],\n\u001b[0m\u001b[1;32m    410\u001b[0m                                    dtype=DTYPE, multi_output=True)\n\u001b[1;32m    411\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    794\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y cannot be None\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 796\u001b[0;31m     X = check_array(X, accept_sparse=accept_sparse,\n\u001b[0m\u001b[1;32m    797\u001b[0m                     \u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    597\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'CANDEY'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from tpot.builtins import StackingEstimator\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from copy import copy\n",
    "\n",
    "# NOTE: Make sure that the outcome column is labeled 'target' in the data file\n",
    "tpot_data = df\n",
    "features = tpot_data.drop('target', axis=1)\n",
    "training_features, testing_features, training_target, testing_target = \\\n",
    "            train_test_split(features, tpot_data['target'], random_state=None)\n",
    "\n",
    "# Average CV score on the training set was: 0.8945711361541637\n",
    "exported_pipeline = make_pipeline(\n",
    "    make_union(\n",
    "        FunctionTransformer(copy),\n",
    "        FunctionTransformer(copy)\n",
    "    ),\n",
    "    GradientBoostingClassifier(learning_rate=0.01, max_depth=3, max_features=0.5, min_samples_leaf=10, min_samples_split=3, n_estimators=100, subsample=0.9500000000000001)\n",
    ")\n",
    "\n",
    "exported_pipeline.fit(training_features, training_target)\n",
    "results = exported_pipeline.predict(testing_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TPOT AutoML Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpot import TPOTRegressor\n",
    "\n",
    "pipeline_optimizer = TPOTRegressor(\n",
    "        scoring = 'f1', \n",
    "        generations=100,\n",
    "        verbosity=2,\n",
    "        n_jobs=-1   # Utilizes all available CPU cores\n",
    "        ) \n",
    "pipeline_optimizer.fit(X_train.drop(['a', 'b', 'TM_A', 'TM_B'],1), y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
